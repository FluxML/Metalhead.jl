var documenterSearchIndex = {"docs":
[{"location":"contributing/#contributing","page":"Contributing to Metalhead","title":"Contribute to Metalhead.jl","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Metalhead","title":"Contributing to Metalhead","text":"We welcome contributions from anyone to Metalhead.jl! Thank you for taking the time to make our ecosystem better.","category":"page"},{"location":"contributing/","page":"Contributing to Metalhead","title":"Contributing to Metalhead","text":"You can contribute by fixing bugs, adding new models, or adding pre-trained weights. If you aren't ready to write some code, but you think you found a bug or have a feature request, please post an issue.","category":"page"},{"location":"contributing/","page":"Contributing to Metalhead","title":"Contributing to Metalhead","text":"Before continuing, make sure you read the FluxML contributing guide for general guidelines and tips.","category":"page"},{"location":"contributing/#Fixing-bugs","page":"Contributing to Metalhead","title":"Fixing bugs","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Metalhead","title":"Contributing to Metalhead","text":"To fix a bug in Metalhead.jl, you can open a PR. It would be helpful to file an issue first so that we can confirm the bug.","category":"page"},{"location":"contributing/#Adding-models","page":"Contributing to Metalhead","title":"Adding models","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Metalhead","title":"Contributing to Metalhead","text":"To add a new model architecture to Metalhead.jl, you can open a PR. Keep in mind a few guiding principles for how this package is designed:","category":"page"},{"location":"contributing/","page":"Contributing to Metalhead","title":"Contributing to Metalhead","text":"reuse layers from Flux as much as possible (e.g. use Parallel before defining a Bottleneck struct)\nadhere as closely as possible to a reference such as a published paper (i.e. the structure of your model should follow intuitively from the paper)\nuse generic functional builders (e.g. Metalhead.resnet is the underlying function that builds \"ResNet-like\" models)\nuse multiple dispatch to add convenience constructors that wrap your functional builder","category":"page"},{"location":"contributing/","page":"Contributing to Metalhead","title":"Contributing to Metalhead","text":"When in doubt, just open a PR! We are more than happy to help review your code to help it align with the rest of the library. After adding a model, you might consider adding some pre-trained weights (see below).","category":"page"},{"location":"contributing/#Adding-pre-trained-weights","page":"Contributing to Metalhead","title":"Adding pre-trained weights","text":"","category":"section"},{"location":"contributing/","page":"Contributing to Metalhead","title":"Contributing to Metalhead","text":"To add pre-trained weights for an existing model or new model, you can open a PR. Below, we describe the steps you should follow to get there.","category":"page"},{"location":"contributing/","page":"Contributing to Metalhead","title":"Contributing to Metalhead","text":"All Metalhead.jl model artifacts are hosted on HuggingFace. You can find the FluxML account here. This documentation from HuggingFace will provide you with an introduction to their ModelHub. In short, the Model Hub is a collection of Git repositories, similar to Julia packages on GitHub. This means you can make a pull request to our HuggingFace repositories to upload updated weight artifacts just like you would make a PR on GitHub to upload code.","category":"page"},{"location":"contributing/","page":"Contributing to Metalhead","title":"Contributing to Metalhead","text":"Train your model or port the weights from another framework.\nSave the model state using BSON.jl with BSON.@save \"modelname.bson\" model_state=Flux.state(model). It is important that your model is saved under the key model_state.\nCompress the saved model as a tarball using tar -cvzf modelname.tar.gz modelname.bson.\nObtain the SHAs (see the Pkg docs). Edit the Artifacts.toml file in the Metalhead.jl repository and add entry for your model. You can leave the URL empty for now.\nOpen a PR on Metalhead.jl. Be sure to ping a maintainer (e.g. @darsnack or @theabhirath) to let us know that you are adding a pre-trained weight. We will create a model repository on HuggingFace if it does not already exist.\nOpen a PR to the corresponding HuggingFace repo. Do this by going to the \"Community\" tab in the HuggingFace repository. PRs and discussions are shown as the same thing in the HuggingFace web app. You can use your local Git program to make clone the repo and make PRs if you wish. Check out the guide on PRs to HuggingFace for more information.\nCopy the download URL for the model file that you added to HuggingFace. Make sure to grab the URL for a specific commit and not for the main branch.\nUpdate your Metalhead.jl PR by adding the URL to the Artifacts.toml.\nIf the tests pass for your weights, we will merge your PR! Your model should pass the acctest function in the Metalhead.jl test suite. If your model already exists in the repo, then these tests are already in place, and you can add your model configuration to the PRETRAINED_MODELS list in the runtests.jl file. Please refer to the ResNet tests as an example.","category":"page"},{"location":"contributing/","page":"Contributing to Metalhead","title":"Contributing to Metalhead","text":"If you want to fix existing weights, then you can follow the same set of steps.","category":"page"},{"location":"contributing/","page":"Contributing to Metalhead","title":"Contributing to Metalhead","text":"See the scripts/ folder in the repo for some helpful scripts that can be used to automate some of these steps.","category":"page"},{"location":"tutorials/quickstart/#A-guide-to-getting-started-with-Metalhead","page":"A guide to getting started with Metalhead","title":"A guide to getting started with Metalhead","text":"","category":"section"},{"location":"tutorials/quickstart/","page":"A guide to getting started with Metalhead","title":"A guide to getting started with Metalhead","text":"Metalhead.jl is a library written in Flux.jl that is a collection of image models, layers and utilities for deep learning in computer vision.","category":"page"},{"location":"tutorials/quickstart/#Model-architectures-and-pre-trained-models","page":"A guide to getting started with Metalhead","title":"Model architectures and pre-trained models","text":"","category":"section"},{"location":"tutorials/quickstart/","page":"A guide to getting started with Metalhead","title":"A guide to getting started with Metalhead","text":"In Metalhead.jl, camel-cased functions mimicking the naming style followed in the paper such as ResNet or MobileNetv3 are considered the \"higher\" level API for models. These are the functions that end-users who do not want to experiment much with model architectures should use. To use these models, simply call the function of the model:","category":"page"},{"location":"tutorials/quickstart/","page":"A guide to getting started with Metalhead","title":"A guide to getting started with Metalhead","text":"using Metalhead\n\nmodel = ResNet(18);","category":"page"},{"location":"tutorials/quickstart/","page":"A guide to getting started with Metalhead","title":"A guide to getting started with Metalhead","text":"The API reference contains the documentation and options for each model function. These models also support the option for loading pre-trained weights from ImageNet.","category":"page"},{"location":"tutorials/quickstart/","page":"A guide to getting started with Metalhead","title":"A guide to getting started with Metalhead","text":"note: Note\nMetalhead is still under active development and thus not all models have pre-trained weights supported. While we are working on expanding the footprint of the pre-trained models, if you would like to help contribute model weights yourself, please check out the contributing guide guide.","category":"page"},{"location":"tutorials/quickstart/","page":"A guide to getting started with Metalhead","title":"A guide to getting started with Metalhead","text":"To use a pre-trained model, just instantiate the model with the pretrain keyword argument set to true:","category":"page"},{"location":"tutorials/quickstart/","page":"A guide to getting started with Metalhead","title":"A guide to getting started with Metalhead","text":"using Metalhead\n  \nmodel = ResNet(18; pretrain = true);","category":"page"},{"location":"tutorials/quickstart/","page":"A guide to getting started with Metalhead","title":"A guide to getting started with Metalhead","text":"Refer to the pretraining guide for more details on how to use pre-trained models.","category":"page"},{"location":"tutorials/quickstart/#More-model-configuration-options","page":"A guide to getting started with Metalhead","title":"More model configuration options","text":"","category":"section"},{"location":"tutorials/quickstart/","page":"A guide to getting started with Metalhead","title":"A guide to getting started with Metalhead","text":"For users who want to use more options for model configuration, Metalhead provides a \"mid-level\" API for models. These are the model functions that are in lowercase such as resnet or mobilenetv3. End-users who want to experiment with model architectures should use these functions. These models do not support the option for loading pre-trained weights from ImageNet out of the box, although one can always load weights explicitly using the loadmodel! function from Flux.","category":"page"},{"location":"tutorials/quickstart/","page":"A guide to getting started with Metalhead","title":"A guide to getting started with Metalhead","text":"To use any of these models, check out the docstrings for the model functions (these are documented in the API reference). Note that these functions typically require more configuration options to be passed in, but offer a lot more flexibility in terms of model architecture. Metalhead defines as many default options as possible so as to make it easier for the user to pick and choose specific options to customise.","category":"page"},{"location":"tutorials/quickstart/#Builders-for-the-advanced-user","page":"A guide to getting started with Metalhead","title":"Builders for the advanced user","text":"","category":"section"},{"location":"tutorials/quickstart/","page":"A guide to getting started with Metalhead","title":"A guide to getting started with Metalhead","text":"For users who want the ability to customise their models as much as possible, Metalhead offers a powerful low-level interface. These are known as builders and allow the user to hack into the core of models and build them up as per their liking. Most users will not need to use builders since a large number of configuration options are exposed at the mid-level API. However, for package developers and users who want to build customised versions of their own models, the low-level API provides the customisability required while still reducing user code.","category":"page"},{"location":"api/densenet/#DenseNet","page":"DenseNet","title":"DenseNet","text":"","category":"section"},{"location":"api/densenet/","page":"DenseNet","title":"DenseNet","text":"This is the API reference for the DenseNet model present in Metalhead.jl.","category":"page"},{"location":"api/densenet/#The-higher-level-model","page":"DenseNet","title":"The higher level model","text":"","category":"section"},{"location":"api/densenet/","page":"DenseNet","title":"DenseNet","text":"DenseNet","category":"page"},{"location":"api/densenet/#Metalhead.DenseNet","page":"DenseNet","title":"Metalhead.DenseNet","text":"DenseNet(config::Int; pretrain = false, growth_rate = 32,\n         reduction = 0.5, inchannels = 3, nclasses = 1000)\n\nCreate a DenseNet model with specified configuration. Currently supported values are (121, 161, 169, 201) (reference).\n\nArguments\n\nconfig: the configuration of the model\npretrain: whether to load the model with pre-trained weights for ImageNet.\ngrowth_rate: the output feature map growth probability of dense blocks (i.e. k in the ref)\nreduction: the factor by which the number of feature maps is scaled across each transition\ninchannels: the number of input channels\nnclasses: the number of output classes\n\nwarning: Warning\nDenseNet does not currently support pretrained weights.\n\nSee also Metalhead.densenet.\n\n\n\n\n\n","category":"type"},{"location":"api/densenet/#The-core-function","page":"DenseNet","title":"The core function","text":"","category":"section"},{"location":"api/densenet/","page":"DenseNet","title":"DenseNet","text":"Metalhead.densenet","category":"page"},{"location":"api/densenet/#Metalhead.densenet","page":"DenseNet","title":"Metalhead.densenet","text":"densenet(nblocks::AbstractVector{Int}; growth_rate = 32,\n         reduction = 0.5, dropout_prob = nothing, inchannels = 3,\n         nclasses = 1000)\n\nCreate a DenseNet model (reference).\n\nArguments\n\nnblocks: number of dense blocks between transitions\ngrowth_rate: the output feature map growth probability of dense blocks (i.e. k in the ref)\nreduction: the factor by which the number of feature maps is scaled across each transition\ndropout_prob: the dropout probability for the classifier head. Set to nothing to disable dropout\ninchannels: the number of input channels\nnclasses: the number of output classes\n\n\n\n\n\n","category":"function"},{"location":"api/efficientnet/#EfficientNet-family-of-models","page":"EfficientNet family of models","title":"EfficientNet family of models","text":"","category":"section"},{"location":"api/efficientnet/","page":"EfficientNet family of models","title":"EfficientNet family of models","text":"This is the API reference for the EfficientNet family of models supported by Metalhead.jl.","category":"page"},{"location":"api/efficientnet/","page":"EfficientNet family of models","title":"EfficientNet family of models","text":"EfficientNet\nEfficientNetv2","category":"page"},{"location":"api/efficientnet/#Metalhead.EfficientNet","page":"EfficientNet family of models","title":"Metalhead.EfficientNet","text":"EfficientNet(config::Symbol; pretrain::Bool = false, inchannels::Integer = 3,\n             nclasses::Integer = 1000)\n\nCreate an EfficientNet model (reference).\n\nArguments\n\nconfig: size of the model. Can be one of [:b0, :b1, :b2, :b3, :b4, :b5, :b6, :b7, :b8].\npretrain: set to true to load the pre-trained weights for ImageNet\ninchannels: number of input channels.\nnclasses: number of output classes.\n\nwarning: Warning\nEfficientNet does not currently support pretrained weights.\n\nSee also Metalhead.efficientnet.\n\n\n\n\n\n","category":"type"},{"location":"api/efficientnet/#Metalhead.EfficientNetv2","page":"EfficientNet family of models","title":"Metalhead.EfficientNetv2","text":"EfficientNetv2(config::Symbol; pretrain::Bool = false, inchannels::Integer = 3,\n               nclasses::Integer = 1000)\n\nCreate an EfficientNetv2 model (reference).\n\nArguments\n\nconfig: size of the network (one of [:small, :medium, :large, :xlarge])\npretrain: whether to load the pre-trained weights for ImageNet\ninchannels: number of input channels\nnclasses: number of output classes\n\nwarning: Warning\nEfficientNetv2 does not currently support pretrained weights.\n\nSee also efficientnet.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/pretrained/#pretrained","page":"Working with pre-trained models from Metalhead","title":"Working with pre-trained models from Metalhead","text":"","category":"section"},{"location":"tutorials/pretrained/","page":"Working with pre-trained models from Metalhead","title":"Working with pre-trained models from Metalhead","text":"Using a model from Metalhead is as simple as selecting a model from the table of available models. For example, below we use the pre-trained ResNet-18 model.","category":"page"},{"location":"tutorials/pretrained/","page":"Working with pre-trained models from Metalhead","title":"Working with pre-trained models from Metalhead","text":"using Metalhead\n  \nmodel = ResNet(18; pretrain = true);","category":"page"},{"location":"tutorials/pretrained/#Using-pre-trained-models-as-feature-extractors","page":"Working with pre-trained models from Metalhead","title":"Using pre-trained models as feature extractors","text":"","category":"section"},{"location":"tutorials/pretrained/","page":"Working with pre-trained models from Metalhead","title":"Working with pre-trained models from Metalhead","text":"The backbone and classifier functions do exactly what their names suggest - they are used to extract the backbone and classifier of a model respectively. For example, to extract the backbone of a pre-trained ResNet-18 model:","category":"page"},{"location":"tutorials/pretrained/","page":"Working with pre-trained models from Metalhead","title":"Working with pre-trained models from Metalhead","text":"backbone(model);","category":"page"},{"location":"tutorials/pretrained/","page":"Working with pre-trained models from Metalhead","title":"Working with pre-trained models from Metalhead","text":"The backbone function could also be useful for people looking to just use specific sections of the model for transfer learning. The function returns a Chain of the layers of the model, so you can easily index into it to get the layers you want. For example, to get the first five layers of a pre-trained ResNet model, you can just write backbone(model)[1:5].","category":"page"},{"location":"tutorials/pretrained/#Training","page":"Working with pre-trained models from Metalhead","title":"Training","text":"","category":"section"},{"location":"tutorials/pretrained/","page":"Working with pre-trained models from Metalhead","title":"Working with pre-trained models from Metalhead","text":"Now, we can use this model with Flux like any other model. First, let's check the accuracy on a test image from ImageNet.","category":"page"},{"location":"tutorials/pretrained/","page":"Working with pre-trained models from Metalhead","title":"Working with pre-trained models from Metalhead","text":"using Images\n\n# test image\nimg = Images.load(download(\"https://cdn.pixabay.com/photo/2015/05/07/11/02/guitar-756326_960_720.jpg\"));","category":"page"},{"location":"tutorials/pretrained/","page":"Working with pre-trained models from Metalhead","title":"Working with pre-trained models from Metalhead","text":"We'll use the popular DataAugmentation.jl library to crop our input image, convert it to a plain array, and normalize the pixels.","category":"page"},{"location":"tutorials/pretrained/","page":"Working with pre-trained models from Metalhead","title":"Working with pre-trained models from Metalhead","text":"using DataAugmentation\nusing Flux\nusing Flux: onecold\n\nDATA_MEAN = (0.485, 0.456, 0.406)\nDATA_STD = (0.229, 0.224, 0.225)\n\naugmentations = CenterCrop((224, 224)) |>\n                ImageToTensor() |>\n                Normalize(DATA_MEAN, DATA_STD)\n\ndata = apply(augmentations, Image(img)) |> itemdata\n\n# ImageNet labels\nlabels = readlines(download(\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"))\n\nprintln(onecold(model(Flux.unsqueeze(data, 4)), labels))","category":"page"},{"location":"tutorials/pretrained/","page":"Working with pre-trained models from Metalhead","title":"Working with pre-trained models from Metalhead","text":"That is fairly accurate! Below, we train the model on some randomly generated data:","category":"page"},{"location":"tutorials/pretrained/","page":"Working with pre-trained models from Metalhead","title":"Working with pre-trained models from Metalhead","text":"using Optimisers\nusing Flux: onehotbatch\nusing Flux.Losses: logitcrossentropy\n\nbatchsize = 1\ndata = [(rand(Float32, 224, 224, 3, batchsize), onehotbatch(rand(1:1000, batchsize), 1:1000))\n        for _ in 1:3]\nopt = Optimisers.Adam()\nstate = Optimisers.setup(rule, model);  # initialise this optimiser's state\nfor (i, (image, y)) in enumerate(data)\n    @info \"Starting batch $i ...\"\n    gs, _ = gradient(model, image) do m, x  # calculate the gradients\n        logitcrossentropy(m(x), y)\n    end;\n    state, model = Optimisers.update(state, model, gs);\nend","category":"page"},{"location":"api/utilities/#Model-utilities","page":"Model Utilities","title":"Model utilities","text":"","category":"section"},{"location":"api/utilities/","page":"Model Utilities","title":"Model Utilities","text":"Metalhead provides some utility functions for making it easier to work with the models inside the library or to build new ones. The API reference for these is documented below.","category":"page"},{"location":"api/utilities/","page":"Model Utilities","title":"Model Utilities","text":"backbone\nclassifier","category":"page"},{"location":"api/utilities/#Metalhead.backbone","page":"Model Utilities","title":"Metalhead.backbone","text":"backbone(model)\n\nThis function returns the backbone of a model that can be used for feature extraction. A Flux.Chain is returned, which can be indexed/sliced into to get the desired layer(s). Note that the model used here as input must be the \"camel-cased\" version of the model, e.g. ResNet instead of resnet.\n\n\n\n\n\n","category":"function"},{"location":"api/utilities/#Metalhead.classifier","page":"Model Utilities","title":"Metalhead.classifier","text":"classifier(model)\n\nThis function returns the classifier head of a model. This is sometimes useful for fine-tuning a model on a different dataset. A Flux.Chain is returned, which can be indexed/sliced into to get the desired layer(s). Note that the model used here as input must be the \"camel-cased\" version of the model, e.g. ResNet instead of resnet.\n\n\n\n\n\n","category":"function"},{"location":"api/others/#Other-models","page":"Other models","title":"Other models","text":"","category":"section"},{"location":"api/others/","page":"Other models","title":"Other models","text":"This is the API reference for some of the other models supported by Metalhead.jl that do not fit into the other categories.","category":"page"},{"location":"api/others/#The-higher-level-model-constructors","page":"Other models","title":"The higher-level model constructors","text":"","category":"section"},{"location":"api/others/","page":"Other models","title":"Other models","text":"AlexNet\nVGG\nSqueezeNet\nUNet","category":"page"},{"location":"api/others/#Metalhead.AlexNet","page":"Other models","title":"Metalhead.AlexNet","text":"AlexNet(; pretrain::Bool = false, inchannels::Integer = 3,\n        nclasses::Integer = 1000)\n\nCreate a AlexNet. (reference).\n\nArguments\n\npretrain: set to true to load pre-trained weights for ImageNet\ninchannels: The number of input channels.\nnclasses: the number of output classes\n\nwarning: Warning\nAlexNet does not currently support pretrained weights.\n\nSee also alexnet.\n\n\n\n\n\n","category":"type"},{"location":"api/others/#Metalhead.VGG","page":"Other models","title":"Metalhead.VGG","text":"VGG(imsize::Dims{2}; config, inchannels, batchnorm = false, nclasses, fcsize, dropout_prob)\n\nConstruct a VGG model with the specified input image size. Typically, the image size is (224, 224).\n\nKeyword Arguments:\n\nconfig : VGG convolutional block configuration. It is defined as a vector of tuples (output_channels, num_convolutions) for each block\ninchannels: number of input channels\nbatchnorm: set to true to use batch normalization after each convolution\nnclasses: number of output classes\nfcsize: intermediate fully connected layer size (see Metalhead.vgg_classifier_layers)\ndropout_prob: dropout level between fully connected layers\n\n\n\n\n\n","category":"type"},{"location":"api/others/#Metalhead.SqueezeNet","page":"Other models","title":"Metalhead.SqueezeNet","text":"SqueezeNet(; pretrain::Bool = false, inchannels::Integer = 3,\n           nclasses::Integer = 1000)\n\nCreate a SqueezeNet (reference).\n\nArguments\n\npretrain: set to true to load the pre-trained weights for ImageNet\ninchannels: number of input channels.\nnclasses: the number of output classes.\n\nSee also squeezenet.\n\n\n\n\n\n","category":"type"},{"location":"api/others/#Metalhead.UNet","page":"Other models","title":"Metalhead.UNet","text":"UNet(imsize::Dims{2} = (256, 256), inchannels::Integer = 3, outplanes::Integer = 3,\n     encoder_backbone = Metalhead.backbone(DenseNet(121)); pretrain::Bool = false)\n\nCreates a UNet model with an encoder built of specified backbone. By default it uses  DenseNet backbone, but any ResNet-like Metalhead model can be used for the encoder. (reference).\n\nArguments\n\nimsize: size of input image\ninchannels: number of channels in input image\noutplanes: number of output feature planes.\nencoder_backbone: The backbone layers of specified model to be used as encoder. For example, Metalhead.backbone(Metalhead.ResNet(18)) can be passed to instantiate a UNet with layers of resnet18 as encoder.\npretrain: Whether to load the pre-trained weights for ImageNet\n\nwarning: Warning\nUNet does not currently support pretrained weights.\n\nSee also Metalhead.unet.\n\n\n\n\n\n","category":"type"},{"location":"api/others/#The-mid-level-functions","page":"Other models","title":"The mid-level functions","text":"","category":"section"},{"location":"api/others/","page":"Other models","title":"Other models","text":"Metalhead.alexnet\nMetalhead.vgg\nMetalhead.squeezenet\nMetalhead.unet","category":"page"},{"location":"api/others/#Metalhead.alexnet","page":"Other models","title":"Metalhead.alexnet","text":"alexnet(; dropout_prob = 0.5, inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreate an AlexNet model (reference).\n\nArguments\n\ndropout_prob: dropout probability for the classifier\ninchannels: The number of input channels.\nnclasses: the number of output classes\n\n\n\n\n\n","category":"function"},{"location":"api/others/#Metalhead.vgg","page":"Other models","title":"Metalhead.vgg","text":"vgg(imsize; config, inchannels, batchnorm = false, nclasses, fcsize, dropout_prob)\n\nCreate a VGG model (reference).\n\nArguments\n\nimsize: input image width and height as a tuple\nconfig: the configuration for the convolution layers (see Metalhead.vgg_convolutional_layers)\ninchannels: number of input channels\nbatchnorm: set to true to use batch normalization after each convolution\nnclasses: number of output classes\nfcsize: intermediate fully connected layer size (see Metalhead.vgg_classifier_layers)\ndropout_prob: dropout level between fully connected layers\n\n\n\n\n\n","category":"function"},{"location":"api/others/#Metalhead.squeezenet","page":"Other models","title":"Metalhead.squeezenet","text":"squeezenet(; dropout_prob = 0.5, inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreate a SqueezeNet model. (reference).\n\nArguments\n\ndropout_prob: dropout probability for the classifier head. Set to nothing to disable dropout.\ninchannels: number of input channels.\nnclasses: the number of output classes.\n\n\n\n\n\n","category":"function"},{"location":"api/others/#Metalhead.unet","page":"Other models","title":"Metalhead.unet","text":"unet(encoder_backbone, imgdims, outplanes::Integer, final::Any = unet_final_block,\n     fdownscale::Integer = 0)\n\nCreates a UNet model with specified convolutional backbone.  Backbone of any Metalhead ResNet-like model can be used as encoder  (reference).\n\nArguments\n\n- `encoder_backbone`: The backbone layers of specified model to be used as encoder.\n\tFor example, `Metalhead.backbone(Metalhead.ResNet(18))` can be passed \n\tto instantiate a UNet with layers of resnet18 as encoder.\n- `inputsize`: size of input image\n- `outplanes`: number of output feature planes\n- `final`: final block as described in original paper\n- `fdownscale`: downscale factor\n\n\n\n\n\n","category":"function"},{"location":"api/inception/#Inception-family-of-models","page":"Inception family of models","title":"Inception family of models","text":"","category":"section"},{"location":"api/inception/","page":"Inception family of models","title":"Inception family of models","text":"This is the API reference for the Inception family of models supported by Metalhead.jl.","category":"page"},{"location":"api/inception/#The-higher-level-model-constructors","page":"Inception family of models","title":"The higher-level model constructors","text":"","category":"section"},{"location":"api/inception/","page":"Inception family of models","title":"Inception family of models","text":"GoogLeNet\nInceptionv3\nInceptionv4\nInceptionResNetv2\nXception","category":"page"},{"location":"api/inception/#Metalhead.GoogLeNet","page":"Inception family of models","title":"Metalhead.GoogLeNet","text":"GoogLeNet(; pretrain::Bool = false, inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreate an Inception-v1 model (commonly referred to as GoogLeNet) (reference).\n\nArguments\n\npretrain: set to true to load the model with pre-trained weights for ImageNet\nnclasses: the number of output classes\nbatchnorm: set to true to use batch normalization after each convolution\nbias: set to true to use bias in the convolution layers\n\nwarning: Warning\nGoogLeNet does not currently support pretrained weights.\n\nSee also Metalhead.googlenet.\n\n\n\n\n\n","category":"type"},{"location":"api/inception/#Metalhead.Inceptionv3","page":"Inception family of models","title":"Metalhead.Inceptionv3","text":"Inceptionv3(; pretrain::Bool = false, inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreate an Inception-v3 model (reference).\n\nArguments\n\npretrain: set to true to load the pre-trained weights for ImageNet\ninchannels: number of input channels\nnclasses: the number of output classes\n\nwarning: Warning\nInceptionv3 does not currently support pretrained weights.\n\nSee also Metalhead.inceptionv3.\n\n\n\n\n\n","category":"type"},{"location":"api/inception/#Metalhead.Inceptionv4","page":"Inception family of models","title":"Metalhead.Inceptionv4","text":"Inceptionv4(; pretrain::Bool = false, inchannels::Integer = 3,\n            nclasses::Integer = 1000)\n\nCreates an Inceptionv4 model. (reference)\n\nArguments\n\npretrain: set to true to load the pre-trained weights for ImageNet\ninchannels: number of input channels.\nnclasses: the number of output classes.\n\nwarning: Warning\nInceptionv4 does not currently support pretrained weights.\n\nSee also Metalhead.inceptionv4.\n\n\n\n\n\n","category":"type"},{"location":"api/inception/#Metalhead.InceptionResNetv2","page":"Inception family of models","title":"Metalhead.InceptionResNetv2","text":"InceptionResNetv2(; pretrain::Bool = false, inchannels::Integer = 3, \n                  nclasses::Integer = 1000)\n\nCreates an InceptionResNetv2 model. (reference)\n\nArguments\n\npretrain: set to true to load the pre-trained weights for ImageNet\ninchannels: number of input channels.\nnclasses: the number of output classes.\n\nwarning: Warning\nInceptionResNetv2 does not currently support pretrained weights.\n\nSee also Metalhead.inceptionresnetv2.\n\n\n\n\n\n","category":"type"},{"location":"api/inception/#Metalhead.Xception","page":"Inception family of models","title":"Metalhead.Xception","text":"Xception(; pretrain::Bool = false, inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates an Xception model. (reference)\n\nArguments\n\npretrain: set to true to load the pre-trained weights for ImageNet.\ninchannels: number of input channels.\nnclasses: the number of output classes.\n\nwarning: Warning\nXception does not currently support pretrained weights.\n\nSee also Metalhead.xception.\n\n\n\n\n\n","category":"type"},{"location":"api/inception/#The-mid-level-functions","page":"Inception family of models","title":"The mid-level functions","text":"","category":"section"},{"location":"api/inception/","page":"Inception family of models","title":"Inception family of models","text":"Metalhead.googlenet\nMetalhead.inceptionv3\nMetalhead.inceptionv4\nMetalhead.inceptionresnetv2\nMetalhead.xception","category":"page"},{"location":"api/inception/#Metalhead.googlenet","page":"Inception family of models","title":"Metalhead.googlenet","text":"googlenet(; dropout_prob = 0.4, inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreate an Inception-v1 model (commonly referred to as GoogLeNet) (reference).\n\nArguments\n\ndropout_prob: the dropout probability in the classifier head. Set to nothing to disable dropout.\ninchannels: the number of input channels\nnclasses: the number of output classes\nbatchnorm: set to true to include batch normalization after each convolution\nbias: set to true to use bias in the convolution layers\n\n\n\n\n\n","category":"function"},{"location":"api/inception/#Metalhead.inceptionv3","page":"Inception family of models","title":"Metalhead.inceptionv3","text":"inceptionv3(; dropout_prob = 0.2, inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreate an Inception-v3 model (reference).\n\nArguments\n\ndropout_prob: the dropout probability in the classifier head. Set to nothing to disable dropout.\ninchannels: number of input feature maps\nnclasses: the number of output classes\n\n\n\n\n\n","category":"function"},{"location":"api/inception/#Metalhead.inceptionv4","page":"Inception family of models","title":"Metalhead.inceptionv4","text":"inceptionv4(; dropout_prob = nothing, inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreate an Inceptionv4 model. (reference)\n\nArguments\n\ndropout_prob: probability of dropout in classifier head. Set to nothing to disable dropout.\ninchannels: number of input channels.\nnclasses: the number of output classes.\n\n\n\n\n\n","category":"function"},{"location":"api/inception/#Metalhead.inceptionresnetv2","page":"Inception family of models","title":"Metalhead.inceptionresnetv2","text":"inceptionresnetv2(; inchannels::Integer = 3, dropout_prob = nothing, nclasses::Integer = 1000)\n\nCreates an InceptionResNetv2 model. (reference)\n\nArguments\n\ndropout_prob: probability of dropout in classifier head. Set to nothing to disable dropout.\ninchannels: number of input channels.\nnclasses: the number of output classes.\n\n\n\n\n\n","category":"function"},{"location":"api/inception/#Metalhead.xception","page":"Inception family of models","title":"Metalhead.xception","text":"xception(; dropout_prob = nothing, inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates an Xception model. (reference)\n\nArguments\n\ndropout_prob: probability of dropout in classifier head. Set to nothing to disable dropout.\ninchannels: number of input channels.\nnclasses: the number of output classes.\n\n\n\n\n\n","category":"function"},{"location":"howto/resnet/#Using-the-ResNet-model-family-in-Metalhead.jl","page":"Using the ResNet model family in Metalhead.jl","title":"Using the ResNet model family in Metalhead.jl","text":"","category":"section"},{"location":"howto/resnet/","page":"Using the ResNet model family in Metalhead.jl","title":"Using the ResNet model family in Metalhead.jl","text":"ResNets are one of the most common convolutional neural network (CNN) models used today. Originally proposed by He et al. in Deep Residual Learning for Image Recognition, they use a residual structure to learn identity mappings that strengthens gradient propagation, thereby helping to prevent the vanishing gradient problem and allow the advent of truly deep neural networks as used today.","category":"page"},{"location":"howto/resnet/","page":"Using the ResNet model family in Metalhead.jl","title":"Using the ResNet model family in Metalhead.jl","text":"Many variants on the original ResNet structure have since become widely used such as Wide-ResNet, ResNeXt, SE-ResNet and Res2Net. Apart from suggesting modifications to the structure of the residual block, papers have also suggested modifying the stem of the network, adding newer regularisation options in the form of stochastic depth and DropBlock, and changing the downsampling path for the blocks to improve performance.","category":"page"},{"location":"howto/resnet/","page":"Using the ResNet model family in Metalhead.jl","title":"Using the ResNet model family in Metalhead.jl","text":"Metalhead provides an extensible, hackable yet powerful interface for working with ResNets that provides built-in toggles for commonly used options in papers and other deep learning libraries, while also allowing the user to build custom model structures if they want very easily.","category":"page"},{"location":"howto/resnet/#Pre-trained-models","page":"Using the ResNet model family in Metalhead.jl","title":"Pre-trained models","text":"","category":"section"},{"location":"howto/resnet/","page":"Using the ResNet model family in Metalhead.jl","title":"Using the ResNet model family in Metalhead.jl","text":"Metalhead provides a variety of pretrained models in the ResNet family to allow users to get started quickly with tasks like transfer learning. Pretrained models for ResNet with depth 18, 34, 50, 101 and 152 is supported, as is WideResNet with depths 50 and 101. ResNeXt also supports some configurations of pretrained models - to know more, check out the documentation for the model.","category":"page"},{"location":"howto/resnet/","page":"Using the ResNet model family in Metalhead.jl","title":"Using the ResNet model family in Metalhead.jl","text":"This is as easy as setting the pretrain keyword to true when constructing the model. For example, to load a pretrained ResNet with depth 50, you can do the following:","category":"page"},{"location":"howto/resnet/","page":"Using the ResNet model family in Metalhead.jl","title":"Using the ResNet model family in Metalhead.jl","text":"using Metalhead\n\nmodel = ResNet(50; pretrain=true)","category":"page"},{"location":"howto/resnet/","page":"Using the ResNet model family in Metalhead.jl","title":"Using the ResNet model family in Metalhead.jl","text":"To check out more about using pretrained models, check out the pretrained models guide.","category":"page"},{"location":"howto/resnet/#The-mid-level-function","page":"Using the ResNet model family in Metalhead.jl","title":"The mid-level function","text":"","category":"section"},{"location":"howto/resnet/","page":"Using the ResNet model family in Metalhead.jl","title":"Using the ResNet model family in Metalhead.jl","text":"Metalhead also provides a function for users looking to customise the ResNet family of models further. This function is named Metalhead.resnet and has a detailed docstring that describes all the various customisation options. You may want to open the above link in another tab, because we're going to be referring to it extensively to build a ResNet model of our liking.","category":"page"},{"location":"howto/resnet/","page":"Using the ResNet model family in Metalhead.jl","title":"Using the ResNet model family in Metalhead.jl","text":"First, let's take a peek at how we would write the vanilla ResNet-18 model using this function. At its core, a residual network is a convolutional network split into stages, where each stage contains a \"residual\" block repeated several times. The Metalhead.jl design reflects this. While there are many keyword arguments that we can configure, there are two required positional argumentsâ€“the block type and the number of times a block is repeated in each stage. For all other options, the default values work well. The original ResNet paper suggest using a \"basic block\" type and a block repetition of two. So we can write the ResNet-18 model as follows:","category":"page"},{"location":"howto/resnet/","page":"Using the ResNet model family in Metalhead.jl","title":"Using the ResNet model family in Metalhead.jl","text":"resnet18 = Metalhead.resnet(Metalhead.basicblock, [2, 2, 2, 2])","category":"page"},{"location":"howto/resnet/","page":"Using the ResNet model family in Metalhead.jl","title":"Using the ResNet model family in Metalhead.jl","text":"What if we want to customise the number of output classes? That's easy; the model has several keyword arguments, one of which allows this. The docstring tells us that it is nclasses, and so we can write:","category":"page"},{"location":"howto/resnet/","page":"Using the ResNet model family in Metalhead.jl","title":"Using the ResNet model family in Metalhead.jl","text":"resnet18 = Metalhead.resnet(Metalhead.basicblock, [2, 2, 2, 2]; nclasses = 10)","category":"page"},{"location":"howto/resnet/","page":"Using the ResNet model family in Metalhead.jl","title":"Using the ResNet model family in Metalhead.jl","text":"Let's try customising this further. Say I want to make a ResNet-50-like model, but with StochasticDepth to provide even more regularisation, and also a custom pooling layer such as AdaptiveMeanMaxPool. Both of these options are provided by Metalhead out of the box, and so we can write:","category":"page"},{"location":"howto/resnet/","page":"Using the ResNet model family in Metalhead.jl","title":"Using the ResNet model family in Metalhead.jl","text":"using Metalhead: Layers # AdaptiveMeanMaxPool is in the Layers module in Metalhead\n\ncustom_resnet = Metalhead.resnet(Metalhead.bottleneck, [3, 4, 6, 3];\n                                 pool_layer = Layers.AdaptiveMeanMaxPool((1, 1)),\n                                 stochastic_depth_prob = 0.2)","category":"page"},{"location":"howto/resnet/","page":"Using the ResNet model family in Metalhead.jl","title":"Using the ResNet model family in Metalhead.jl","text":"To make this a ResNeXt-like model, all we need to do is configure the cardinality and the  base width:","category":"page"},{"location":"howto/resnet/","page":"Using the ResNet model family in Metalhead.jl","title":"Using the ResNet model family in Metalhead.jl","text":"custom_resnet = Metalhead.resnet(Metalhead.bottleneck, [3, 4, 6, 3];\n                                 cardinality = 32, base_width = 4,\n                                 pool_layer = Layers.AdaptiveMeanMaxPool((1, 1)),\n                                 stochastic_depth_prob = 0.2)","category":"page"},{"location":"howto/resnet/","page":"Using the ResNet model family in Metalhead.jl","title":"Using the ResNet model family in Metalhead.jl","text":"And we have a custom model, built with minimal effort! The documentation for Metalhead.resnet has been written with extensive care and in as much detail as possible to facilitate ease of use. Still, if you find anything difficult to understand, feel free to open an issue and we will be happy to help you out, and to improve the documentation where necessary.","category":"page"},{"location":"api/mobilenet/#MobileNet-family-of-models","page":"MobileNet family of models","title":"MobileNet family of models","text":"","category":"section"},{"location":"api/mobilenet/","page":"MobileNet family of models","title":"MobileNet family of models","text":"This is the API reference for the MobileNet family of models supported by Metalhead.jl.","category":"page"},{"location":"api/mobilenet/","page":"MobileNet family of models","title":"MobileNet family of models","text":"MobileNetv1\nMobileNetv2\nMobileNetv3\nMNASNet","category":"page"},{"location":"api/mobilenet/#Metalhead.MobileNetv1","page":"MobileNet family of models","title":"Metalhead.MobileNetv1","text":"MobileNetv1(width_mult::Real = 1; pretrain::Bool = false,\n            inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreate a MobileNetv1 model with the baseline configuration (reference).\n\nArguments\n\nwidth_mult: Controls the number of output feature maps in each block (with 1 being the default in the paper; this is usually a value between 0.1 and 1.4)\npretrain: Whether to load the pre-trained weights for ImageNet\ninchannels: The number of input channels.\nnclasses: The number of output classes\n\nwarning: Warning\nMobileNetv1 does not currently support pretrained weights.\n\nSee also Metalhead.mobilenetv1.\n\n\n\n\n\n","category":"type"},{"location":"api/mobilenet/#Metalhead.MobileNetv2","page":"MobileNet family of models","title":"Metalhead.MobileNetv2","text":"MobileNetv2(width_mult = 1.0; inchannels::Integer = 3, pretrain::Bool = false,\n            nclasses::Integer = 1000)\n\nCreate a MobileNetv2 model with the specified configuration. (reference).\n\nArguments\n\nwidth_mult: Controls the number of output feature maps in each block (with 1 being the default in the paper; this is usually a value between 0.1 and 1.4)\npretrain: Whether to load the pre-trained weights for ImageNet\ninchannels: The number of input channels.\nnclasses: The number of output classes\n\nwarning: Warning\nMobileNetv2 does not currently support pretrained weights.\n\nSee also Metalhead.mobilenetv2.\n\n\n\n\n\n","category":"type"},{"location":"api/mobilenet/#Metalhead.MobileNetv3","page":"MobileNet family of models","title":"Metalhead.MobileNetv3","text":"MobileNetv3(config::Symbol; width_mult::Real = 1, pretrain::Bool = false,\n            inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreate a MobileNetv3 model with the specified configuration. (reference). Set pretrain = true to load the model with pre-trained weights for ImageNet.\n\nArguments\n\nconfig: :small or :large for the size of the model (see paper).\nwidth_mult: Controls the number of output feature maps in each block (with 1 being the default in the paper; this is usually a value between 0.1 and 1.4)\npretrain: whether to load the pre-trained weights for ImageNet\ninchannels: number of input channels\nnclasses: the number of output classes\n\nwarning: Warning\nMobileNetv3 does not currently support pretrained weights.\n\nSee also Metalhead.mobilenetv3.\n\n\n\n\n\n","category":"type"},{"location":"api/mobilenet/#Metalhead.MNASNet","page":"MobileNet family of models","title":"Metalhead.MNASNet","text":"MNASNet(config::Symbol; width_mult::Real = 1, pretrain::Bool = false,\n        inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a MNASNet model with the specified configuration. (reference)\n\nArguments\n\nconfig: configuration of the model. One of B1, A1 or small. B1 is without squeeze-and-excite layers, A1 is with squeeze-and-excite layers, and small is a smaller version of A1.\nwidth_mult: Controls the number of output feature maps in each block (with 1 being the default in the paper; this is usually a value between 0.1 and 1.4)\npretrain: Whether to load the pre-trained weights for ImageNet\ninchannels: The number of input channels.\nnclasses: The number of output classes\n\nwarning: Warning\nMNASNet does not currently support pretrained weights.\n\nSee also Metalhead.mnasnet.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Layers","page":"Layers","title":"Layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Metalhead also defines a module called Layers which contains some custom layers that are used to configure the models in Metalhead. These layers are not available in Flux at present. To use the functions defined in the Layers module, you need to import it.","category":"page"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"using Metalhead: Layers","category":"page"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"This page contains the API reference for the Layers module.","category":"page"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"warning: Warning\nThe Layers module is still a work in progress. While we will endeavour to keep the API stable, we cannot guarantee that it will not change in the future. If you find any of the functions in this module do not work as expected, please open an issue on GitHub.","category":"page"},{"location":"api/layers/#Convolution-BatchNorm-layers","page":"Layers","title":"Convolution + BatchNorm layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Metalhead.Layers.conv_norm\nMetalhead.Layers.basic_conv_bn","category":"page"},{"location":"api/layers/#Metalhead.Layers.conv_norm","page":"Layers","title":"Metalhead.Layers.conv_norm","text":"conv_norm(kernel_size::Dims{2}, inplanes::Integer, outplanes::Integer,\n          activation = relu; norm_layer = BatchNorm, revnorm::Bool = false,\n          preact::Bool = false, stride::Integer = 1, pad::Integer = 0,\n          dilation::Integer = 1, groups::Integer = 1, [bias, weight, init])\n\nCreate a convolution + normalisation layer pair with activation.\n\nArguments\n\nkernel_size: size of the convolution kernel (tuple)\ninplanes: number of input feature maps\noutplanes: number of output feature maps\nactivation: the activation function for the final layer\nnorm_layer: the normalisation layer used. Note that using identity as the normalisation layer will result in no normalisation being applied. (This is only compatible with preact and revnorm both set to false.)\nrevnorm: set to true to place the normalisation layer before the convolution\npreact: set to true to place the activation function before the normalisation layer (only compatible with revnorm = false)\nbias: bias for the convolution kernel. This is set to false by default if norm_layer is not identity and true otherwise.\nstride: stride of the convolution kernel\npad: padding of the convolution kernel\ndilation: dilation of the convolution kernel\ngroups: groups for the convolution kernel\nweight, init: initialization for the convolution kernel (see Flux.Conv)\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Metalhead.Layers.basic_conv_bn","page":"Layers","title":"Metalhead.Layers.basic_conv_bn","text":"basic_conv_bn(kernel_size::Dims{2}, inplanes, outplanes, activation = relu;\n              kwargs...)\n\nReturns a convolution + batch normalisation pair with activation as used by the Inception family of models with default values matching those used in the official TensorFlow implementation.\n\nArguments\n\nkernel_size: size of the convolution kernel (tuple)\ninplanes: number of input feature maps\noutplanes: number of output feature maps\nactivation: the activation function for the final layer\nbatchnorm: set to true to include batch normalization after each convolution\nkwargs: keyword arguments passed to conv_norm\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Convolution-related-custom-blocks","page":"Layers","title":"Convolution-related custom blocks","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"These blocks are designed to be used in convolutional neural networks. Most of these are used in the MobileNet and EfficientNet family of models, but they also feature in \"fancier\" versions of well known-models like ResNet (SE-ResNet).","category":"page"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Metalhead.Layers.dwsep_conv_norm\nMetalhead.Layers.mbconv\nMetalhead.Layers.fused_mbconv\nMetalhead.Layers.squeeze_excite\nMetalhead.Layers.effective_squeeze_excite","category":"page"},{"location":"api/layers/#Metalhead.Layers.dwsep_conv_norm","page":"Layers","title":"Metalhead.Layers.dwsep_conv_norm","text":"dwsep_conv_norm(kernel_size::Dims{2}, inplanes::Integer, outplanes::Integer,\n                activation = relu; norm_layer = BatchNorm, stride::Integer = 1,\n                bias::Bool = !(norm_layer !== identity), pad::Integer = 0, [bias, weight, init])\n\nCreate a depthwise separable convolution chain as used in MobileNetv1. This is sequence of layers:\n\na kernel_size depthwise convolution from inplanes => inplanes\na (batch) normalisation layer + activation (if norm_layer !== identity; otherwise activation is applied to the convolution output)\na kernel_size convolution from inplanes => outplanes\na (batch) normalisation layer + activation (if norm_layer !== identity; otherwise activation is applied to the convolution output)\n\nSee Fig. 3 in reference.\n\nArguments\n\nkernel_size: size of the convolution kernel (tuple)\ninplanes: number of input feature maps\noutplanes: number of output feature maps\nactivation: the activation function for the final layer\nnorm_layer: the normalisation layer used. Note that using identity as the normalisation layer will result in no normalisation being applied.\nbias: whether to use bias in the convolution layers.\nstride: stride of the first convolution kernel\npad: padding of the first convolution kernel\nweight, init: initialization for the convolution kernel (see Flux.Conv)\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Metalhead.Layers.mbconv","page":"Layers","title":"Metalhead.Layers.mbconv","text":"mbconv(kernel_size::Dims{2}, inplanes::Integer, explanes::Integer,\n       outplanes::Integer, activation = relu; stride::Integer,\n       reduction::Union{Nothing, Real} = nothing,\n       se_round_fn = x -> round(Int, x), norm_layer = BatchNorm, kwargs...)\n\nCreate a basic inverted residual block for MobileNet and Efficient variants. This is a sequence of layers:\n\na 1x1 convolution from inplanes => explanes followed by a (batch) normalisation layer\nactivation if inplanes != explanes\na kernel_size depthwise separable convolution from explanes => explanes\na (batch) normalisation layer\na squeeze-and-excitation block (if reduction != nothing) from explanes => se_round_fn(explanes / reduction) and back to explanes\na 1x1 convolution from explanes => outplanes\na (batch) normalisation layer + activation\n\nwarning: Warning\nThis function does not handle the residual connection by default. The user must add this manually to use this block as a standalone. To construct a model, check out the builders, which handle the residual connection and other details.\n\nFirst introduced in the MobileNetv2 paper. (See Fig. 3 in reference.)\n\nArguments\n\nkernel_size: kernel size of the convolutional layers\ninplanes: number of input feature maps\nexplanes: The number of expanded feature maps. This is the number of feature maps after the first 1x1 convolution.\noutplanes: The number of output feature maps\nactivation: The activation function for the first two convolution layer\nstride: The stride of the convolutional kernel, has to be either 1 or 2\nreduction: The reduction factor for the number of hidden feature maps in a squeeze and excite layer (see squeeze_excite)\nse_round_fn: The function to round the number of reduced feature maps in the squeeze and excite layer\nnorm_layer: The normalization layer to use\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Metalhead.Layers.fused_mbconv","page":"Layers","title":"Metalhead.Layers.fused_mbconv","text":"fused_mbconv(kernel_size::Dims{2}, inplanes::Integer, explanes::Integer,\n             outplanes::Integer, activation = relu;\n             stride::Integer, norm_layer = BatchNorm)\n\nCreate a fused inverted residual block.\n\nThis is a sequence of layers:\n\na kernel_size depthwise separable convolution from explanes => explanes\na (batch) normalisation layer\na 1x1 convolution from explanes => outplanes followed by a (batch) normalisation layer + activation if inplanes != explanes\n\nwarning: Warning\nThis function does not handle the residual connection by default. The user must add this manually to use this block as a standalone. To construct a model, check out the builders, which handle the residual connection and other details.\n\nOriginally introduced by Google in EfficientNet-EdgeTPU: Creating Accelerator-Optimized Neural Networks with AutoML. Later used in the EfficientNetv2 paper.\n\nArguments\n\nkernel_size: kernel size of the convolutional layers\ninplanes: number of input feature maps\nexplanes: The number of expanded feature maps\noutplanes: The number of output feature maps\nactivation: The activation function for the first two convolution layer\nstride: The stride of the convolutional kernel, has to be either 1 or 2\nnorm_layer: The normalization layer to use\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Metalhead.Layers.squeeze_excite","page":"Layers","title":"Metalhead.Layers.squeeze_excite","text":"squeeze_excite(inplanes::Integer; reduction::Real = 16, round_fn = _round_channels, \n               norm_layer = identity, activation = relu, gate_activation = sigmoid)\n\nCreates a squeeze-and-excitation layer used in MobileNets, EfficientNets and SE-ResNets.\n\nArguments\n\ninplanes: The number of input feature maps\nreduction: The reduction factor for the number of hidden feature maps in the squeeze and excite layer. The number of hidden feature maps is calculated as round_fn(inplanes / reduction).\nround_fn: The function to round the number of reduced feature maps.\nactivation: The activation function for the first convolution layer\ngate_activation: The activation function for the gate layer\nnorm_layer: The normalization layer to be used after the convolution layers\nrd_planes: The number of hidden feature maps in a squeeze and excite layer\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Metalhead.Layers.effective_squeeze_excite","page":"Layers","title":"Metalhead.Layers.effective_squeeze_excite","text":"effective_squeeze_excite(inplanes, gate_activation = sigmoid)\n\nEffective squeeze-and-excitation layer. (reference: CenterMask : Real-Time Anchor-Free Instance Segmentation)\n\nArguments\n\ninplanes: The number of input feature maps\ngate_activation: The activation function for the gate layer\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Normalisation,-Dropout-and-Pooling-layers","page":"Layers","title":"Normalisation, Dropout and Pooling layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Metalhead provides various custom layers for normalisation, dropout and pooling which have been used to additionally customise various models.","category":"page"},{"location":"api/layers/#Normalisation-layers","page":"Layers","title":"Normalisation layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Metalhead.Layers.ChannelLayerNorm\nMetalhead.Layers.LayerNormV2\nMetalhead.Layers.LayerScale","category":"page"},{"location":"api/layers/#Metalhead.Layers.ChannelLayerNorm","page":"Layers","title":"Metalhead.Layers.ChannelLayerNorm","text":"ChannelLayerNorm(sz::Integer, Î» = identity; eps = 1.0f-6)\n\nA variant of LayerNorm where the input is normalised along the channel dimension. The input is expected to have channel dimension with size sz. It also applies a learnable shift and rescaling after the normalization.\n\nNote that this is specifically for inputs with 4 dimensions in the format (H, W, C, N) where H, W are the height and width of the input, C is the number of channels, and N is the batch size.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Metalhead.Layers.LayerNormV2","page":"Layers","title":"Metalhead.Layers.LayerNormV2","text":"LayerNormV2(size..., Î»=identity; affine=true, eps=1f-5)\n\nSame as Flux's LayerNorm but eps is added before taking the square root in the denominator. Therefore, LayerNormV2 matches pytorch's LayerNorm.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Metalhead.Layers.LayerScale","page":"Layers","title":"Metalhead.Layers.LayerScale","text":"LayerScale(planes::Integer, Î»)\n\nCreates a Flux.Scale layer that performs \"LayerScale\" (reference).\n\nArguments\n\nplanes: Size of channel dimension in the input.\nÎ»: initialisation value for the learnable diagonal matrix.\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Dropout-layers","page":"Layers","title":"Dropout layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Metalhead.Layers.DropBlock\nMetalhead.Layers.dropblock\nMetalhead.Layers.StochasticDepth","category":"page"},{"location":"api/layers/#Metalhead.Layers.DropBlock","page":"Layers","title":"Metalhead.Layers.DropBlock","text":"DropBlock(drop_block_prob = 0.1, block_size = 7, gamma_scale = 1.0, [rng])\n\nThe DropBlock layer. While training, it zeroes out continguous regions of size block_size in the input. During inference, it simply returns the input x. It can be used in two ways: either with all blocks having the same survival probability or with a linear scaling rule across the blocks. This is performed only at training time. At test time, the DropBlock layer is equivalent to identity.\n\n(reference)\n\nArguments\n\ndrop_block_prob: probability of dropping a block. If nothing is passed, it returns identity. Note that some literature uses the term \"survival probability\" instead, which is equivalent to 1 - drop_block_prob.\nblock_size: size of the block to drop\ngamma_scale: multiplicative factor for gamma used. For the calculation of gamma, refer to the paper.\nrng: can be used to pass in a custom RNG instead of the default. Custom RNGs are only supported on the CPU.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Metalhead.Layers.dropblock","page":"Layers","title":"Metalhead.Layers.dropblock","text":"dropblock([rng], x::AbstractArray{T, 4}, drop_block_prob, block_size,\n          gamma_scale, active::Bool = true)\n\nThe dropblock function. If active is true, for each input, it zeroes out continguous regions of size block_size in the input. Otherwise, it simply returns the input x.\n\nArguments\n\nrng: can be used to pass in a custom RNG instead of the default. Custom RNGs are only supported on the CPU.\nx: input array\ndrop_block_prob: probability of dropping a block. If nothing is passed, it returns identity.\nblock_size: size of the block to drop\ngamma_scale: multiplicative factor for gamma used. For the calculations, refer to the paper.\n\nIf you are not a package developer, you most likely do not want this function. Use DropBlock instead.\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Metalhead.Layers.StochasticDepth","page":"Layers","title":"Metalhead.Layers.StochasticDepth","text":"StochasticDepth(p, mode = :row; [rng])\n\nImplements Stochastic Depth. This is a Dropout layer from Flux that drops values with probability p. (reference)\n\nThis layer can be used to drop certain blocks in a residual structure and allow them to propagate completely through the skip connection. It can be used in two ways: either with all blocks having the same survival probability or with a linear scaling rule across the blocks. This is performed only at training time. At test time, the StochasticDepth layer is equivalent to identity.\n\nArguments\n\np: probability of Stochastic Depth. Note that some literature uses the term \"survival probability\" instead, which is equivalent to 1 - p.\nmode: Either :batch or :row. :batch randomly zeroes the entire input, row zeroes randomly selected rows from the batch. The default is :row.\nrng: can be used to pass in a custom RNG instead of the default. See Flux.Dropout for more information on the behaviour of this argument. Custom RNGs are only supported on the CPU.\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Pooling-layers","page":"Layers","title":"Pooling layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Metalhead.Layers.AdaptiveMeanMaxPool","category":"page"},{"location":"api/layers/#Metalhead.Layers.AdaptiveMeanMaxPool","page":"Layers","title":"Metalhead.Layers.AdaptiveMeanMaxPool","text":"AdaptiveMeanMaxPool([connection = +], output_size::Tuple = (1, 1))\n\nA type of adaptive pooling layer which uses both mean and max pooling and combines them to produce a single output. Note that this is equivalent to Parallel(connection, AdaptiveMeanPool(output_size), AdaptiveMaxPool(output_size)). When connection is not specified, it defaults to +.\n\nArguments\n\nconnection: The connection type to use.\noutput_size: The size of the output after pooling.\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Classifier-creation","page":"Layers","title":"Classifier creation","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Metalhead provides a function to create a classifier for neural network models that is quite flexible, and is used by the library extensively to create the classifier \"head\" for networks.","category":"page"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Metalhead.Layers.create_classifier","category":"page"},{"location":"api/layers/#Metalhead.Layers.create_classifier","page":"Layers","title":"Metalhead.Layers.create_classifier","text":"create_classifier(inplanes::Integer, nclasses::Integer, activation = identity;\n                  use_conv::Bool = false, pool_layer = AdaptiveMeanPool((1, 1)), \n                  dropout_prob = nothing)\n\nCreates a classifier head to be used for models.\n\nArguments\n\ninplanes: number of input feature maps\nnclasses: number of output classes\nactivation: activation function to use\nuse_conv: whether to use a 1x1 convolutional layer instead of a Dense layer.\npool_layer: pooling layer to use. This is passed in with the layer instantiated with any arguments that are needed i.e. as AdaptiveMeanPool((1, 1)), for example.\ndropout_prob: dropout probability used in the classifier head. Set to nothing to disable dropout.\n\n\n\n\n\ncreate_classifier(inplanes::Integer, hidden_planes::Integer, nclasses::Integer,\n                  activations::NTuple{2} = (relu, identity);\n                  use_conv::NTuple{2, Bool} = (false, false),\n                  pool_layer = AdaptiveMeanPool((1, 1)), dropout_prob = nothing)\n\nCreates a classifier head to be used for models with an extra hidden layer.\n\nArguments\n\ninplanes: number of input feature maps\nhidden_planes: number of hidden feature maps\nnclasses: number of output classes\nactivations: activation functions to use for the hidden and output layers. This is a tuple of two elements, the first being the activation function for the hidden layer and the second for the output layer.\nuse_conv: whether to use a 1x1 convolutional layer instead of a Dense layer. This is a tuple of two booleans, the first for the hidden layer and the second for the output layer.\npool_layer: pooling layer to use. This is passed in with the layer instantiated with any arguments that are needed i.e. as AdaptiveMeanPool((1, 1)), for example.\ndropout_prob: dropout probability used in the classifier head. Set to nothing to disable dropout.\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Vision-transformer-related-layers","page":"Layers","title":"Vision transformer-related layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"The Layers module contains specific layers that are used to build vision transformer (ViT)-inspired models:","category":"page"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Metalhead.Layers.MultiHeadSelfAttention\nMetalhead.Layers.ClassTokens\nMetalhead.Layers.ViPosEmbedding\nMetalhead.Layers.PatchEmbedding","category":"page"},{"location":"api/layers/#Metalhead.Layers.MultiHeadSelfAttention","page":"Layers","title":"Metalhead.Layers.MultiHeadSelfAttention","text":"MultiHeadSelfAttention(planes::Integer, nheads::Integer = 8; qkv_bias::Bool = false, \n            attn_dropout_prob = 0., proj_dropout_prob = 0.)\n\nMulti-head self-attention layer.\n\nArguments\n\nplanes: number of input channels\nnheads: number of heads\nqkv_bias: whether to use bias in the layer to get the query, key and value\nattn_dropout_prob: dropout probability after the self-attention layer\nproj_dropout_prob: dropout probability after the projection layer\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Metalhead.Layers.ClassTokens","page":"Layers","title":"Metalhead.Layers.ClassTokens","text":"ClassTokens(planes::Integer; init = Flux.zeros32)\n\nAppends class tokens to an input with embedding dimension planes for use in many vision transformer models.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Metalhead.Layers.ViPosEmbedding","page":"Layers","title":"Metalhead.Layers.ViPosEmbedding","text":"ViPosEmbedding(embedsize::Integer, npatches::Integer; \n               init = (dims::Dims{2}) -> rand(Float32, dims))\n\nPositional embedding layer used by many vision transformer-like models.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Metalhead.Layers.PatchEmbedding","page":"Layers","title":"Metalhead.Layers.PatchEmbedding","text":"PatchEmbedding(imsize::Dims{2} = (224, 224); inchannels::Integer = 3,\n               patch_size::Dims{2} = (16, 16), embedplanes = 768,\n               norm_layer = planes -> identity, flatten = true)\n\nPatch embedding layer used by many vision transformer-like models to split the input image into patches.\n\nArguments\n\nimsize: the size of the input image\ninchannels: number of input channels\npatch_size: the size of the patches\nembedplanes: the number of channels in the embedding\nnorm_layer: the normalization layer - by default the identity function but otherwise takes a single argument constructor for a normalization layer like LayerNorm or BatchNorm\nflatten: set true to flatten the input spatial dimensions after the embedding\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#MLPMixer-related-blocks","page":"Layers","title":"MLPMixer-related blocks","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Apart from this, the Layers module also contains certain blocks used in MLPMixer-style models:","category":"page"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Metalhead.Layers.gated_mlp_block\nMetalhead.Layers.mlp_block","category":"page"},{"location":"api/layers/#Metalhead.Layers.gated_mlp_block","page":"Layers","title":"Metalhead.Layers.gated_mlp_block","text":"gated_mlp(gate_layer, inplanes::Integer, hidden_planes::Integer, \n          outplanes::Integer = inplanes; dropout_prob = 0.0, activation = gelu)\n\nFeedforward block based on the implementation in the paper \"Pay Attention to MLPs\". (reference)\n\nArguments\n\ngate_layer: Layer to use for the gating.\ninplanes: Number of dimensions in the input.\nhidden_planes: Number of dimensions in the intermediate layer.\noutplanes: Number of dimensions in the output - by default it is the same as inplanes.\ndropout_prob: Dropout probability.\nactivation: Activation function to use.\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Metalhead.Layers.mlp_block","page":"Layers","title":"Metalhead.Layers.mlp_block","text":"mlp_block(inplanes::Integer, hidden_planes::Integer, outplanes::Integer = inplanes; \n          dropout_prob = 0., activation = gelu)\n\nFeedforward block used in many MLPMixer-like and vision-transformer models.\n\nArguments\n\ninplanes: Number of dimensions in the input.\nhidden_planes: Number of dimensions in the intermediate layer.\noutplanes: Number of dimensions in the output - by default it is the same as inplanes.\ndropout_prob: Dropout probability.\nactivation: Activation function to use.\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Utilities-for-layers","page":"Layers","title":"Utilities for layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"These are some miscellaneous utilities present in the Layers module, and are used with other custom/inbuilt layers to make certain common operations in neural networks easier.","category":"page"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Metalhead.Layers.inputscale\nMetalhead.Layers.actadd\nMetalhead.Layers.addact\nMetalhead.Layers.cat_channels\nMetalhead.Layers.flatten_chains\nMetalhead.Layers.linear_scheduler\nMetalhead.Layers.swapdims","category":"page"},{"location":"api/layers/#Metalhead.Layers.inputscale","page":"Layers","title":"Metalhead.Layers.inputscale","text":"inputscale(Î»; activation = identity)\n\nScale the input by a scalar Î» and applies an activation function to it. Equivalent to activation.(Î» .* x).\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Metalhead.Layers.actadd","page":"Layers","title":"Metalhead.Layers.actadd","text":"actadd(activation = relu, xs...)\n\nConvenience function for adding input arrays after applying an activation function to them. Useful as the connection argument for the block function in resnet.\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Metalhead.Layers.addact","page":"Layers","title":"Metalhead.Layers.addact","text":"addact(activation = relu, xs...)\n\nConvenience function for applying an activation function to the output after summing up the input arrays. Useful as the connection argument for the block function in resnet.\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Metalhead.Layers.cat_channels","page":"Layers","title":"Metalhead.Layers.cat_channels","text":"cat_channels(x, y, zs...)\n\nConcatenate x and y (and any zs) along the channel dimension (third dimension). Equivalent to cat(x, y, zs...; dims=3). Convenient reduction operator for use with Parallel.\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Metalhead.Layers.flatten_chains","page":"Layers","title":"Metalhead.Layers.flatten_chains","text":"flatten_chains(m::Chain)\nflatten_chains(m)\n\nConvenience function for traversing nested layers of a Chain object and flatten them  into a single iterator.\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Metalhead.Layers.linear_scheduler","page":"Layers","title":"Metalhead.Layers.linear_scheduler","text":"linear_scheduler(drop_prob = 0.0; start_value = 0.0, depth)\nlinear_scheduler(drop_prob::Nothing; depth::Integer)\n\nReturns the dropout probabilities for a given depth using the linear scaling rule. Note that this returns evenly spaced values between start_value and drop_prob, not including drop_prob. If drop_prob is nothing, it returns a Vector of length depth with all values equal to nothing.\n\n\n\n\n\n","category":"function"},{"location":"api/layers/#Metalhead.Layers.swapdims","page":"Layers","title":"Metalhead.Layers.swapdims","text":"swapdims(perm)\n\nConvenience function that returns a closure which permutes the dimensions of an array. perm is a vector or tuple specifying a permutation of the input dimensions. Equivalent to permutedims(x, perm).\n\n\n\n\n\n","category":"function"},{"location":"api/mixers/#MLPMixer-like-models","page":"MLPMixer-like models","title":"MLPMixer-like models","text":"","category":"section"},{"location":"api/mixers/","page":"MLPMixer-like models","title":"MLPMixer-like models","text":"This is the API reference for the MLPMixer-like models supported by Metalhead.jl.","category":"page"},{"location":"api/mixers/#The-higher-level-model-constructors","page":"MLPMixer-like models","title":"The higher-level model constructors","text":"","category":"section"},{"location":"api/mixers/","page":"MLPMixer-like models","title":"MLPMixer-like models","text":"MLPMixer\nResMLP\ngMLP","category":"page"},{"location":"api/mixers/#Metalhead.MLPMixer","page":"MLPMixer-like models","title":"Metalhead.MLPMixer","text":"MLPMixer(config::Symbol; patch_size::Dims{2} = (16, 16), imsize::Dims{2} = (224, 224),\n         inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a model with the MLPMixer architecture. (reference).\n\nArguments\n\nconfig: the size of the model - one of :small, :base, :large or :huge\npatch_size: the size of the patches\nimsize: the size of the input image\nstochastic_depth_prob: Stochastic depth probability\ninchannels: the number of input channels\nnclasses: number of output classes\n\nSee also Metalhead.mlpmixer.\n\n\n\n\n\n","category":"type"},{"location":"api/mixers/#Metalhead.ResMLP","page":"MLPMixer-like models","title":"Metalhead.ResMLP","text":"ResMLP(config::Symbol; patch_size::Dims{2} = (16, 16), imsize::Dims{2} = (224, 224),\n       inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a model with the ResMLP architecture. (reference).\n\nArguments\n\nconfig: the size of the model - one of :small, :base, :large or :huge\npatch_size: the size of the patches\nimsize: the size of the input image\ninchannels: the number of input channels\nnclasses: number of output classes\n\nSee also Metalhead.mlpmixer.\n\n\n\n\n\n","category":"type"},{"location":"api/mixers/#Metalhead.gMLP","page":"MLPMixer-like models","title":"Metalhead.gMLP","text":"gMLP(config::Symbol; patch_size::Dims{2} = (16, 16), imsize::Dims{2} = (224, 224),\n     inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a model with the gMLP architecture. (reference).\n\nArguments\n\nconfig: the size of the model - one of :small, :base, :large or :huge\npatch_size: the size of the patches\nimsize: the size of the input image\ninchannels: the number of input channels\nnclasses: number of output classes\n\nSee also Metalhead.mlpmixer.\n\n\n\n\n\n","category":"type"},{"location":"api/mixers/#The-core-MLPMixer-function","page":"MLPMixer-like models","title":"The core MLPMixer function","text":"","category":"section"},{"location":"api/mixers/","page":"MLPMixer-like models","title":"MLPMixer-like models","text":"Metalhead.mlpmixer","category":"page"},{"location":"api/mixers/#Metalhead.mlpmixer","page":"MLPMixer-like models","title":"Metalhead.mlpmixer","text":"mlpmixer(block, imsize::Dims{2} = (224, 224); inchannels::Integer = 3, norm_layer = LayerNorm,\n         patch_size::Dims{2} = (16, 16), embedplanes = 512, stochastic_depth_prob = 0.,\n         depth::Integer = 12, nclasses::Integer = 1000, kwargs...)\n\nCreates a model with the MLPMixer architecture. (reference).\n\nArguments\n\nblock: the type of mixer block to use in the model - architecture dependent (a constructor of the form block(embedplanes, npatches; stochastic_depth_prob, kwargs...))\nimsize: the size of the input image\ninchannels: the number of input channels\nnorm_layer: the normalization layer to use in the model\npatch_size: the size of the patches\nembedplanes: the number of channels after the patch embedding (denotes the hidden dimension)\nstochastic_depth_prob: Stochastic depth probability\ndepth: the number of blocks in the model\nnclasses: number of output classes\nkwargs: additional arguments (if any) to pass to the mixer block. Will use the defaults if not specified.\n\n\n\n\n\n","category":"function"},{"location":"api/mixers/#The-block-functions","page":"MLPMixer-like models","title":"The block functions","text":"","category":"section"},{"location":"api/mixers/","page":"MLPMixer-like models","title":"MLPMixer-like models","text":"Metalhead.mixerblock\nMetalhead.resmixerblock\nMetalhead.SpatialGatingUnit\nMetalhead.spatialgatingblock","category":"page"},{"location":"api/mixers/#Metalhead.mixerblock","page":"MLPMixer-like models","title":"Metalhead.mixerblock","text":"mixerblock(planes::Integer, npatches::Integer; mlp_layer = mlp_block,\n           mlp_ratio = (0.5, 4.0), dropout_prob = 0.0, stochastic_depth_prob = 0.0,\n           activation = gelu)\n\nCreates a feedforward block for the MLPMixer architecture. (reference)\n\nArguments\n\nplanes: the number of planes in the block\nnpatches: the number of patches of the input\nmlp_ratio: number(s) that determine(s) the number of hidden channels in the token mixing MLP and/or the channel mixing MLP as a ratio to the number of planes in the block.\nmlp_layer: the MLP layer to use in the block\ndropout_prob: the dropout probability to use in the MLP blocks\nstochastic_depth_prob: Stochastic depth probability\nactivation: the activation function to use in the MLP blocks\n\n\n\n\n\n","category":"function"},{"location":"api/mixers/#Metalhead.resmixerblock","page":"MLPMixer-like models","title":"Metalhead.resmixerblock","text":"resmixerblock(planes, npatches; dropout_prob = 0., stochastic_depth_prob = 0., mlp_ratio = 4.0,\n              activation = gelu, layerscale_init = 1e-4)\n\nCreates a block for the ResMixer architecture. (reference).\n\nArguments\n\nplanes: the number of planes in the block\nnpatches: the number of patches of the input\nmlp_ratio: ratio of the number of hidden channels in the channel mixing MLP to the number of planes in the block\nmlp_layer: the MLP block to use\ndropout_prob: the dropout probability to use in the MLP blocks\nstochastic_depth_prob: Stochastic depth probability\nactivation: the activation function to use in the MLP blocks\nlayerscale_init: initialisation constant for the LayerScale\n\n\n\n\n\n","category":"function"},{"location":"api/mixers/#Metalhead.SpatialGatingUnit","page":"MLPMixer-like models","title":"Metalhead.SpatialGatingUnit","text":"SpatialGatingUnit(planes::Integer, npatches::Integer; norm_layer = LayerNorm)\n\nCreates a spatial gating unit as described in the gMLP paper. (reference)\n\nArguments\n\nplanes: the number of planes in the block\nnpatches: the number of patches of the input\nnorm_layer: the normalisation layer to use\n\n\n\n\n\n","category":"type"},{"location":"api/mixers/#Metalhead.spatialgatingblock","page":"MLPMixer-like models","title":"Metalhead.spatialgatingblock","text":"spatialgatingblock(planes::Integer, npatches::Integer; mlp_ratio = 4.0,\n                   norm_layer = LayerNorm, mlp_layer = gated_mlp_block,\n                   dropout_prob = 0.0, stochastic_depth_prob = 0.0,\n                   activation = gelu)\n\nCreates a feedforward block based on the gMLP model architecture described in the paper. (reference)\n\nArguments\n\nplanes: the number of planes in the block\nnpatches: the number of patches of the input\nmlp_ratio: ratio of the number of hidden channels in the channel mixing MLP to the number of planes in the block\nnorm_layer: the normalisation layer to use\ndropout_prob: the dropout probability to use in the MLP blocks\nstochastic_depth_prob: Stochastic depth probability\nactivation: the activation function to use in the MLP blocks\n\n\n\n\n\n","category":"function"},{"location":"api/vit/#Vision-Transformer-models","page":"Vision Transformer models","title":"Vision Transformer models","text":"","category":"section"},{"location":"api/vit/","page":"Vision Transformer models","title":"Vision Transformer models","text":"This is the API reference for the Vision Transformer models supported by Metalhead.jl.","category":"page"},{"location":"api/vit/#The-higher-level-model-constructors","page":"Vision Transformer models","title":"The higher-level model constructors","text":"","category":"section"},{"location":"api/vit/","page":"Vision Transformer models","title":"Vision Transformer models","text":"ViT","category":"page"},{"location":"api/vit/#Metalhead.ViT","page":"Vision Transformer models","title":"Metalhead.ViT","text":"ViT(config::Symbol = base; imsize::Dims{2} = (224, 224), inchannels::Integer = 3,\n    patch_size::Dims{2} = (16, 16), pool = :class, nclasses::Integer = 1000)\n\nCreates a Vision Transformer (ViT) model. (reference).\n\nArguments\n\nconfig: the model configuration, one of [:tiny, :small, :base, :large, :huge, :giant, :gigantic]\nimsize: image size\ninchannels: number of input channels\npatch_size: size of the patches\npool: pooling type, either :class or :mean\nnclasses: number of classes in the output\n\nSee also Metalhead.vit.\n\n\n\n\n\n","category":"type"},{"location":"api/vit/#The-mid-level-functions","page":"Vision Transformer models","title":"The mid-level functions","text":"","category":"section"},{"location":"api/vit/","page":"Vision Transformer models","title":"Vision Transformer models","text":"Metalhead.vit","category":"page"},{"location":"api/vit/#Metalhead.vit","page":"Vision Transformer models","title":"Metalhead.vit","text":"vit(imsize::Dims{2} = (256, 256); inchannels::Integer = 3, patch_size::Dims{2} = (16, 16),\n    embedplanes = 768, depth = 6, nheads = 16, mlp_ratio = 4.0, dropout_prob = 0.1,\n    emb_dropout_prob = 0.1, pool = :class, nclasses::Integer = 1000)\n\nCreates a Vision Transformer (ViT) model. (reference).\n\nArguments\n\nimsize: image size\ninchannels: number of input channels\npatch_size: size of the patches\nembedplanes: the number of channels after the patch embedding\ndepth: number of blocks in the transformer\nnheads: number of attention heads in the transformer\nmlpplanes: number of hidden channels in the MLP block in the transformer\ndropout_prob: dropout probability\nemb_dropout: dropout probability for the positional embedding layer\npool: pooling type, either :class or :mean\nnclasses: number of classes in the output\n\n\n\n\n\n","category":"function"},{"location":"api/resnet/#ResNet-like-models","page":"ResNet-like models","title":"ResNet-like models","text":"","category":"section"},{"location":"api/resnet/","page":"ResNet-like models","title":"ResNet-like models","text":"This is the API reference for the ResNet inspired model structures present in Metalhead.jl.","category":"page"},{"location":"api/resnet/#The-higher-level-model-constructors","page":"ResNet-like models","title":"The higher-level model constructors","text":"","category":"section"},{"location":"api/resnet/","page":"ResNet-like models","title":"ResNet-like models","text":"ResNet\nWideResNet\nResNeXt\nSEResNet\nSEResNeXt\nRes2Net\nRes2NeXt","category":"page"},{"location":"api/resnet/#Metalhead.ResNet","page":"ResNet-like models","title":"Metalhead.ResNet","text":"ResNet(depth::Integer; pretrain::Bool = false, inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a ResNet model with the specified depth. (reference)\n\nArguments\n\ndepth: one of [18, 34, 50, 101, 152]. The depth of the ResNet model.\npretrain: set to true to load the model with pre-trained weights for ImageNet\ninchannels: The number of input channels.\nnclasses: the number of output classes\n\nAdvanced users who want more configuration options will be better served by using resnet.\n\n\n\n\n\n","category":"type"},{"location":"api/resnet/#Metalhead.WideResNet","page":"ResNet-like models","title":"Metalhead.WideResNet","text":"WideResNet(depth::Integer; pretrain::Bool = false, inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a Wide ResNet model with the specified depth. The model is the same as ResNet except for the bottleneck number of channels which is twice larger in every block. The number of channels in outer 1x1 convolutions is the same. (reference)\n\nArguments\n\ndepth: one of [18, 34, 50, 101, 152]. The depth of the Wide ResNet model.\npretrain: set to true to load the model with pre-trained weights for ImageNet\ninchannels: The number of input channels.\nnclasses: The number of output classes\n\nAdvanced users who want more configuration options will be better served by using resnet.\n\n\n\n\n\n","category":"type"},{"location":"api/resnet/#Metalhead.ResNeXt","page":"ResNet-like models","title":"Metalhead.ResNeXt","text":"ResNeXt(depth::Integer; pretrain::Bool = false, cardinality::Integer = 32,\n        base_width::Integer = 4, inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a ResNeXt model with the specified depth, cardinality, and base width. (reference)\n\nArguments\n\ndepth: one of [50, 101, 152]. The depth of the ResNet model.\npretrain: set to true to load the model with pre-trained weights for ImageNet. Supported configurations are:\ndepth 50, cardinality of 32 and base width of 4.\ndepth 101, cardinality of 32 and base width of 8.\ndepth 101, cardinality of 64 and base width of 4.\ncardinality: the number of groups to be used in the 3x3 convolution in each block.\nbase_width: the number of feature maps in each group.\ninchannels: the number of input channels.\nnclasses: the number of output classes\n\nAdvanced users who want more configuration options will be better served by using resnet.\n\n\n\n\n\n","category":"type"},{"location":"api/resnet/#Metalhead.SEResNet","page":"ResNet-like models","title":"Metalhead.SEResNet","text":"SEResNet(depth::Integer; pretrain::Bool = false, inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a SEResNet model with the specified depth. (reference)\n\nArguments\n\ndepth: one of [18, 34, 50, 101, 152]. The depth of the ResNet model.\npretrain: set to true to load the model with pre-trained weights for ImageNet\ninchannels: the number of input channels.\nnclasses: the number of output classes\n\nwarning: Warning\nSEResNet does not currently support pretrained weights.\n\nAdvanced users who want more configuration options will be better served by using resnet.\n\n\n\n\n\n","category":"type"},{"location":"api/resnet/#Metalhead.SEResNeXt","page":"ResNet-like models","title":"Metalhead.SEResNeXt","text":"SEResNeXt(depth::Integer; pretrain::Bool = false, cardinality::Integer = 32,\n          base_width::Integer = 4, inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a SEResNeXt model with the specified depth, cardinality, and base width. (reference)\n\nArguments\n\ndepth: one of [50, 101, 152]. The depth of the ResNet model.\npretrain: set to true to load the model with pre-trained weights for ImageNet\ncardinality: the number of groups to be used in the 3x3 convolution in each block.\nbase_width: the number of feature maps in each group.\ninchannels: the number of input channels\nnclasses: the number of output classes\n\nwarning: Warning\nSEResNeXt does not currently support pretrained weights.\n\nAdvanced users who want more configuration options will be better served by using resnet.\n\n\n\n\n\n","category":"type"},{"location":"api/resnet/#Metalhead.Res2Net","page":"ResNet-like models","title":"Metalhead.Res2Net","text":"Res2Net(depth::Integer; pretrain::Bool = false, scale::Integer = 4,\n        base_width::Integer = 26, inchannels::Integer = 3,\n        nclasses::Integer = 1000)\n\nCreates a Res2Net model with the specified depth, scale, and base width. (reference)\n\nArguments\n\ndepth: one of [50, 101, 152]. The depth of the Res2Net model.\npretrain: set to true to load the model with pre-trained weights for ImageNet\nscale: the number of feature groups in the block. See the paper for more details.\nbase_width: the number of feature maps in each group.\ninchannels: the number of input channels.\nnclasses: the number of output classes\n\nwarning: Warning\nRes2Net does not currently support pretrained weights.\n\nAdvanced users who want more configuration options will be better served by using resnet.\n\n\n\n\n\n","category":"type"},{"location":"api/resnet/#Metalhead.Res2NeXt","page":"ResNet-like models","title":"Metalhead.Res2NeXt","text":"Res2NeXt(depth::Integer; pretrain::Bool = false, scale::Integer = 4,\n         base_width::Integer = 4, cardinality::Integer = 8,\n         inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a Res2NeXt model with the specified depth, scale, base width and cardinality. (reference)\n\nArguments\n\ndepth: one of [50, 101, 152]. The depth of the Res2Net model.\npretrain: set to true to load the model with pre-trained weights for ImageNet\nscale: the number of feature groups in the block. See the paper for more details.\nbase_width: the number of feature maps in each group.\ncardinality: the number of groups in the 3x3 convolutions.\ninchannels: the number of input channels.\nnclasses: the number of output classes\n\nwarning: Warning\nRes2NeXt does not currently support pretrained weights.\n\nAdvanced users who want more configuration options will be better served by using resnet.\n\n\n\n\n\n","category":"type"},{"location":"api/resnet/#The-mid-level-function","page":"ResNet-like models","title":"The mid-level function","text":"","category":"section"},{"location":"api/resnet/","page":"ResNet-like models","title":"ResNet-like models","text":"Metalhead.resnet","category":"page"},{"location":"api/resnet/#Metalhead.resnet","page":"ResNet-like models","title":"Metalhead.resnet","text":"resnet(block_type, block_repeats::AbstractVector{<:Integer},\n       downsample_opt::NTuple{2, Any} = (downsample_conv, downsample_identity);\n       cardinality::Integer = 1, base_width::Integer = 64,\n       inplanes::Integer = 64, reduction_factor::Integer = 1,\n       connection = addact, activation = relu,\n       norm_layer = BatchNorm, revnorm::Bool = false,\n       attn_fn = planes -> identity, pool_layer = AdaptiveMeanPool((1, 1)),\n       use_conv::Bool = false, dropblock_prob = nothing,\n       stochastic_depth_prob = nothing, dropout_prob = nothing,\n       imsize::Dims{2} = (256, 256), inchannels::Integer = 3,\n       nclasses::Integer = 1000, kwargs...)\n\nCreates a generic ResNet-like model that is used to create The higher-level model constructors like ResNet, Wide ResNet, ResNeXt and Res2Net. For an even more generic model API, see Metalhead.build_resnet.\n\nArguments\n\nblock_type: The type of block to be used in the model. This can be one of Metalhead.basicblock, Metalhead.bottleneck and Metalhead.bottle2neck. basicblock is used in the original ResNet paper for ResNet-18 and ResNet-34, and bottleneck is used in the original ResNet-50 and ResNet-101 models, as well as for the Wide ResNet and ResNeXt models. bottle2neck is introduced in the Res2Net paper.\nblock_repeats: A Vector of integers specifying the number of times each block is repeated in each stage of the ResNet model. For example, [3, 4, 6, 3] is the configuration used in ResNet-50, which has 3 blocks in the first stage, 4 blocks in the second stage, 6 blocks in the third stage and 3 blocks in the fourth stage.\ndownsample_opt: A NTuple of two callbacks that are used to determine the downsampling operation to be used in the model. The first callback is used to determine the convolutional operation to be used in the downsampling operation and the second callback is used to determine the identity operation to be used in the downsampling operation.\ncardinality: The number of groups to be used in the 3x3 convolutional layer in the bottleneck block. This is usually modified from the default value of 1 in the ResNet models to 32 or 64 in the ResNeXt models.\nbase_width: The base width of the convolutional layer in the blocks of the model.\ninplanes: The number of input channels in the first convolutional layer.\nreduction_factor: The reduction factor used in the model.\nconnection: This is a function that determines the residual connection in the model. For resnets, either of Metalhead.addact or Metalhead.actadd is recommended. These decide whether the residual connection is added before or after the activation function.\nnorm_layer: The normalisation layer to be used in the model.\nrevnorm: set to true to place the normalisation layers before the convolutions\nattn_fn: A callback that is used to determine the attention function to be used in the model. See Metalhead.Layers.squeeze_excite for an example.\npool_layer: A fully-instantiated pooling layer passed in to be used by the classifier head. For example, AdaptiveMeanPool((1, 1)) is used in the ResNet family by default, but something like MeanPool((3, 3)) should also work provided the dimensions after applying the pooling layer are compatible with the rest of the classifier head.\nuse_conv: Set to true to use convolutions instead of identity operations in the model.\ndropblock_prob: DropBlock probability to be used in the model. Set to nothing to disable DropBlock. See Metalhead.DropBlock for more details.\nstochastic_depth_prob: StochasticDepth probability to be used in the model. Set to nothing to disable StochasticDepth. See Metalhead.StochasticDepth for more details.\ndropout_prob: Dropout probability to be used in the classifier head. Set to nothing to disable Dropout.\nimsize: The size of the input (height, width).\ninchannels: The number of input channels.\nnclasses: The number of output classes.\nkwargs: Additional keyword arguments to be passed to the block builder (note: ignore this argument if you are not sure what it does. To know more about how this works, check out the section of the documentation that talks about builders in Metalhead and specifically for the ResNet block functions).\n\n\n\n\n\n","category":"function"},{"location":"api/resnet/#Lower-level-functions-and-builders","page":"ResNet-like models","title":"Lower-level functions and builders","text":"","category":"section"},{"location":"api/resnet/#Block-functions","page":"ResNet-like models","title":"Block functions","text":"","category":"section"},{"location":"api/resnet/","page":"ResNet-like models","title":"ResNet-like models","text":"Metalhead.basicblock\nMetalhead.bottleneck\nMetalhead.bottle2neck","category":"page"},{"location":"api/resnet/#Metalhead.basicblock","page":"ResNet-like models","title":"Metalhead.basicblock","text":"basicblock(inplanes::Integer, planes::Integer; stride::Integer = 1,\n           reduction_factor::Integer = 1, activation = relu,\n           norm_layer = BatchNorm, revnorm::Bool = false,\n           drop_block = identity, drop_path = identity,\n           attn_fn = planes -> identity)\n\nCreates a basic residual block (see reference). This function creates the layers. For more configuration options and to see the function used to build the block for the model, see Metalhead.basicblock_builder.\n\nArguments\n\ninplanes: number of input feature maps\nplanes: number of feature maps for the block\nstride: the stride of the block\nreduction_factor: the factor by which the input feature maps are reduced before\n\nthe first convolution.\n\nactivation: the activation function to use.\nnorm_layer: the normalization layer to use.\nrevnorm: set to true to place the normalisation layer before the convolution\ndrop_block: the drop block layer\ndrop_path: the drop path layer\nattn_fn: the attention function to use. See squeeze_excite for an example.\n\n\n\n\n\n","category":"function"},{"location":"api/resnet/#Metalhead.bottleneck","page":"ResNet-like models","title":"Metalhead.bottleneck","text":"bottleneck(inplanes::Integer, planes::Integer; stride::Integer,\n           cardinality::Integer = 1, base_width::Integer = 64,\n           reduction_factor::Integer = 1, activation = relu,\n           norm_layer = BatchNorm, revnorm::Bool = false,\n           drop_block = identity, drop_path = identity,\n           attn_fn = planes -> identity)\n\nCreates a bottleneck residual block (see reference). This function creates the layers. For more configuration options and to see the function used to build the block for the model, see Metalhead.bottleneck_builder.\n\nArguments\n\ninplanes: number of input feature maps\nplanes: number of feature maps for the block\nstride: the stride of the block\ncardinality: the number of groups in the convolution.\nbase_width: the number of output feature maps for each convolutional group.\nreduction_factor: the factor by which the input feature maps are reduced before the first convolution.\nactivation: the activation function to use.\nnorm_layer: the normalization layer to use.\nrevnorm: set to true to place the normalisation layer before the convolution\ndrop_block: the drop block layer\ndrop_path: the drop path layer\nattn_fn: the attention function to use. See squeeze_excite for an example.\n\n\n\n\n\n","category":"function"},{"location":"api/resnet/#Metalhead.bottle2neck","page":"ResNet-like models","title":"Metalhead.bottle2neck","text":"bottle2neck(inplanes::Integer, planes::Integer; stride::Integer = 1,\n            cardinality::Integer = 1, base_width::Integer = 26,\n            scale::Integer = 4, activation = relu, norm_layer = BatchNorm,\n            revnorm::Bool = false, attn_fn = planes -> identity)\n\nCreates a bottleneck block as described in the Res2Net paper. (reference) This function creates the layers. For more configuration options and to see the function used to build the block for the model, see Metalhead.bottle2neck_builder.\n\nArguments\n\ninplanes: number of input feature maps\nplanes: number of feature maps for the block\nstride: the stride of the block\ncardinality: the number of groups in the 3x3 convolutions.\nbase_width: the number of output feature maps for each convolutional group.\nscale: the number of feature groups in the block. See the paper for more details.\nactivation: the activation function to use.\nnorm_layer: the normalization layer to use.\nrevnorm: set to true to place the batch norm before the convolution\nattn_fn: the attention function to use. See squeeze_excite for an example.\n\n\n\n\n\n","category":"function"},{"location":"api/resnet/#Downsampling-functions","page":"ResNet-like models","title":"Downsampling functions","text":"","category":"section"},{"location":"api/resnet/","page":"ResNet-like models","title":"ResNet-like models","text":"Metalhead.downsample_identity\nMetalhead.downsample_conv\nMetalhead.downsample_pool","category":"page"},{"location":"api/resnet/#Metalhead.downsample_identity","page":"ResNet-like models","title":"Metalhead.downsample_identity","text":"downsample_identity(inplanes::Integer, outplanes::Integer; kwargs...)\n\nCreates an identity downsample layer. This returns identity if inplanes == outplanes. If outplanes > inplanes, it maps the input to outplanes channels using a 1x1 max pooling layer and zero padding.\n\nwarning: Warning\nThis does not currently support the scenario where inplanes > outplanes.\n\nArguments\n\ninplanes: number of input feature maps\noutplanes: number of output feature maps\n\nNote that kwargs are ignored and only included for compatibility with other downsample layers.\n\n\n\n\n\n","category":"function"},{"location":"api/resnet/#Metalhead.downsample_conv","page":"ResNet-like models","title":"Metalhead.downsample_conv","text":"downsample_conv(inplanes::Integer, outplanes::Integer; stride::Integer = 1,\n                norm_layer = BatchNorm, revnorm::Bool = false)\n\nCreates a 1x1 convolutional downsample layer as used in ResNet.\n\nArguments\n\ninplanes: number of input feature maps\noutplanes: number of output feature maps\nstride: the stride of the convolution\nnorm_layer: the normalization layer to use.\nrevnorm: set to true to place the normalisation layer before the convolution\n\n\n\n\n\n","category":"function"},{"location":"api/resnet/#Metalhead.downsample_pool","page":"ResNet-like models","title":"Metalhead.downsample_pool","text":"downsample_pool(inplanes::Integer, outplanes::Integer; stride::Integer = 1,\n                norm_layer = BatchNorm, revnorm::Bool = false)\n\nCreates a pooling-based downsample layer as described in the Bag of Tricks paper. This adds an average pooling layer of size (2, 2) with stride followed by a 1x1 convolution.\n\nArguments\n\ninplanes: number of input feature maps\noutplanes: number of output feature maps\nstride: the stride of the convolution\nnorm_layer: the normalization layer to use.\nrevnorm: set to true to place the normalisation layer before the convolution\n\n\n\n\n\n","category":"function"},{"location":"api/resnet/#Block-builders","page":"ResNet-like models","title":"Block builders","text":"","category":"section"},{"location":"api/resnet/","page":"ResNet-like models","title":"ResNet-like models","text":"Metalhead.basicblock_builder\nMetalhead.bottleneck_builder\nMetalhead.bottle2neck_builder","category":"page"},{"location":"api/resnet/#Metalhead.basicblock_builder","page":"ResNet-like models","title":"Metalhead.basicblock_builder","text":"basicblock_builder(block_repeats::AbstractVector{<:Integer};\n                   inplanes::Integer = 64, reduction_factor::Integer = 1,\n                   expansion::Integer = 1, norm_layer = BatchNorm,\n                   revnorm::Bool = false, activation = relu,\n                   attn_fn = planes -> identity,\n                   dropblock_prob = nothing, stochastic_depth_prob = nothing,\n                   stride_fn = resnet_stride, planes_fn = resnet_planes,\n                   downsample_tuple = (downsample_conv, downsample_identity))\n\nBuilder for creating a basic block for a ResNet model. (reference)\n\nArguments\n\nblock_repeats: number of repeats of a block in each stage\ninplanes: number of input channels\nreduction_factor: reduction factor for the number of channels in each stage\nexpansion: expansion factor for the number of channels for the block\nnorm_layer: normalization layer to use\nrevnorm: set to true to place normalization layer before the convolution\nactivation: activation function to use\nattn_fn: attention function to use\ndropblock_prob: dropblock probability. Set to nothing to disable DropBlock\nstochastic_depth_prob: stochastic depth probability. Set to nothing to disable StochasticDepth\nstride_fn: callback for computing the stride of the block\nplanes_fn: callback for computing the number of channels in each block\ndownsample_tuple: two-element tuple of downsample functions to use. The first one is used when the number of channels changes in the block, the second one is used when the number of channels stays the same.\n\n\n\n\n\n","category":"function"},{"location":"api/resnet/#Metalhead.bottleneck_builder","page":"ResNet-like models","title":"Metalhead.bottleneck_builder","text":"bottleneck_builder(block_repeats::AbstractVector{<:Integer};\n                   inplanes::Integer = 64, cardinality::Integer = 1,\n                   base_width::Integer = 64, reduction_factor::Integer = 1,\n                   expansion::Integer = 4, norm_layer = BatchNorm,\n                   revnorm::Bool = false, activation = relu,\n                   attn_fn = planes -> identity, dropblock_prob = nothing,\n                   stochastic_depth_prob = nothing, stride_fn = resnet_stride,\n                   planes_fn = resnet_planes,\n                   downsample_tuple = (downsample_conv, downsample_identity))\n\nBuilder for creating a bottleneck block for a ResNet/ResNeXt model. (reference)\n\nArguments\n\nblock_repeats: number of repeats of a block in each stage\ninplanes: number of input channels\ncardinality: number of groups for the convolutional layer\nbase_width: base width for the convolutional layer\nreduction_factor: reduction factor for the number of channels in each stage\nexpansion: expansion factor for the number of channels for the block\nnorm_layer: normalization layer to use\nrevnorm: set to true to place normalization layer before the convolution\nactivation: activation function to use\nattn_fn: attention function to use\ndropblock_prob: dropblock probability. Set to nothing to disable DropBlock\nstochastic_depth_prob: stochastic depth probability. Set to nothing to disable StochasticDepth\nstride_fn: callback for computing the stride of the block\nplanes_fn: callback for computing the number of channels in each block\ndownsample_tuple: two-element tuple of downsample functions to use. The first one is used when the number of channels changes in the block, the second one is used when the number of channels stays the same.\n\n\n\n\n\n","category":"function"},{"location":"api/resnet/#Metalhead.bottle2neck_builder","page":"ResNet-like models","title":"Metalhead.bottle2neck_builder","text":"bottle2neck_builder(block_repeats::AbstractVector{<:Integer};\n                    inplanes::Integer = 64, cardinality::Integer = 1,\n                    base_width::Integer = 26, scale::Integer = 4,\n                    expansion::Integer = 4, norm_layer = BatchNorm,\n                    revnorm::Bool = false, activation = relu,\n                    attn_fn = planes -> identity, stride_fn = resnet_stride,\n                    planes_fn = resnet_planes,\n                    downsample_tuple = (downsample_conv, downsample_identity))\n\nBuilder for creating a bottle2neck block for a Res2Net model. (reference)\n\nArguments\n\nblock_repeats: number of repeats of a block in each stage\ninplanes: number of input channels\ncardinality: number of groups for the convolutional layer\nbase_width: base width for the convolutional layer\nscale: scale for the number of channels in each block\nexpansion: expansion factor for the number of channels for the block\nnorm_layer: normalization layer to use\nrevnorm: set to true to place normalization layer before the convolution\nactivation: activation function to use\nattn_fn: attention function to use\nstride_fn: callback for computing the stride of the block\nplanes_fn: callback for computing the number of channels in each block\ndownsample_tuple: two-element tuple of downsample functions to use. The first one is used when the number of channels changes in the block, the second one is used when the number of channels stays the same.\n\n\n\n\n\n","category":"function"},{"location":"api/resnet/#Generic-ResNet-model-builder","page":"ResNet-like models","title":"Generic ResNet model builder","text":"","category":"section"},{"location":"api/resnet/","page":"ResNet-like models","title":"ResNet-like models","text":"Metalhead.build_resnet","category":"page"},{"location":"api/resnet/#Metalhead.build_resnet","page":"ResNet-like models","title":"Metalhead.build_resnet","text":"build_resnet(img_dims, stem, get_layers, block_repeats::AbstractVector{<:Integer},\n             connection, classifier_fn)\n\nCreates a generic ResNet-like model.\n\ninfo: Info\nThis is a very generic, flexible but low level function that can be used to create any of the ResNet variants. For a more user friendly function, see Metalhead.resnet.\n\nArguments\n\nimg_dims: The dimensions of the input image. This is used to determine the number of feature maps to be passed to the classifier. This should be a tuple of the form (height, width, channels).\nstem: The stem of the ResNet model. The stem should be created outside of this function and passed in as an argument. This is done to allow for more flexibility in creating the stem. resnet_stem is a helper function that Metalhead provides which is recommended for creating the stem.\nget_layers is a function that takes in two inputs - the stage_idx, or the index of the stage, and the block_idx, or the index of the block within the stage. It returns a tuple of layers. If the tuple returned by get_layers has more than one element, then connection is used to splat this tuple into Parallel - if not, then the only element of the tuple is directly inserted into the network. get_layers is a very specific function and should not be created on its own. Instead, use one of the builders provided by Metalhead to create it.\nblock_repeats: This is a Vector of integers that specifies the number of repeats of each block in each stage.\nconnection: This is a function that determines the residual connection in the model. For resnets, either of Metalhead.addact or Metalhead.actadd is recommended.\nclassifier_fn: This is a function that takes in the number of feature maps and returns a classifier. This is usually built as a closure using a function like Metalhead.create_classifier. For example, if the number of output classes is nclasses, then the function can be defined as channels -> create_classifier(channels, nclasses).\n\n\n\n\n\n","category":"function"},{"location":"api/resnet/#Utility-callbacks","page":"ResNet-like models","title":"Utility callbacks","text":"","category":"section"},{"location":"api/resnet/","page":"ResNet-like models","title":"ResNet-like models","text":"Metalhead.resnet_planes\nMetalhead.resnet_stride\nMetalhead.resnet_stem","category":"page"},{"location":"api/resnet/#Metalhead.resnet_planes","page":"ResNet-like models","title":"Metalhead.resnet_planes","text":"resnet_planes(block_repeats::AbstractVector{<:Integer})\n\nDefault callback for determining the number of channels in each block in a ResNet model.\n\nArguments\n\nblock_repeats: A Vector of integers specifying the number of times each block is repeated in each stage of the ResNet model. For example, [3, 4, 6, 3] is the configuration used in ResNet-50, which has 3 blocks in the first stage, 4 blocks in the second stage, 6 blocks in the third stage and 3 blocks in the fourth stage.\n\n\n\n\n\n","category":"function"},{"location":"api/resnet/#Metalhead.resnet_stride","page":"ResNet-like models","title":"Metalhead.resnet_stride","text":"resnet_stride(stage_idx::Integer, block_idx::Integer)\n\nDefault callback for determining the stride of a block in a ResNet model. Returns 2 for the first block in every stage except the first stage and 1 for all other blocks.\n\nArguments\n\nstage_idx: The index of the stage in the ResNet model.\nblock_idx: The index of the block in the stage.\n\n\n\n\n\n","category":"function"},{"location":"api/resnet/#Metalhead.resnet_stem","page":"ResNet-like models","title":"Metalhead.resnet_stem","text":"resnet_stem(; stem_type = :default, inchannels::Integer = 3, replace_stem_pool = false,\n              norm_layer = BatchNorm, activation = relu)\n\nBuilds a stem to be used in a ResNet model. See the stem argument of resnet for details on how to use this function.\n\nArguments\n\nstem_type: The type of stem to be built. One of [:default, :deep, :deep_tiered].\n:default: Builds a stem based on the default ResNet stem, which consists of a single 7x7 convolution with stride 2 and a normalisation layer followed by a 3x3 max pooling layer with stride 2.\n:deep: This borrows ideas from other papers (InceptionResNetv2, for example) in using a deeper stem with 3 successive 3x3 convolutions having normalisation layers after each one. This is followed by a 3x3 max pooling layer with stride 2.\n:deep_tiered: A variant of the :deep stem that has a larger width in the second convolution. This is an experimental variant from the timm library in Python that shows peformance improvements over the :deep stem in some cases.\ninchannels: number of input channels\nreplace_pool: Set to true to replace the max pooling layers with a 3x3 convolution + normalization with a stride of two.\nnorm_layer: The normalisation layer used in the stem.\nactivation: The activation function used in the stem.\n\n\n\n\n\n","category":"function"},{"location":"api/hybrid/#Hybrid-CNN-architectures","page":"Hybrid CNN architectures","title":"Hybrid CNN architectures","text":"","category":"section"},{"location":"api/hybrid/","page":"Hybrid CNN architectures","title":"Hybrid CNN architectures","text":"These models are hybrid CNN architectures that borrow certain ideas from vision transformer models.","category":"page"},{"location":"api/hybrid/#The-higher-level-model-constructors","page":"Hybrid CNN architectures","title":"The higher-level model constructors","text":"","category":"section"},{"location":"api/hybrid/","page":"Hybrid CNN architectures","title":"Hybrid CNN architectures","text":"ConvMixer\nConvNeXt","category":"page"},{"location":"api/hybrid/#Metalhead.ConvMixer","page":"Hybrid CNN architectures","title":"Metalhead.ConvMixer","text":"ConvMixer(config::Symbol; pretrain::Bool = false, inchannels::Integer = 3,\n          nclasses::Integer = 1000)\n\nCreates a ConvMixer model. (reference)\n\nArguments\n\nconfig: the size of the model, either :base, :small or :large\npretrain: whether to load the pre-trained weights for ImageNet\ninchannels: number of input channels\nnclasses: number of classes in the output\n\nwarning: Warning\n\n\nConvMixer does not currently support pretrained weights.\n\nSee also Metalhead.convmixer.\n\n\n\n\n\n","category":"type"},{"location":"api/hybrid/#Metalhead.ConvNeXt","page":"Hybrid CNN architectures","title":"Metalhead.ConvNeXt","text":"ConvNeXt(config::Symbol; pretrain::Bool = true, inchannels::Integer = 3,\n         nclasses::Integer = 1000)\n\nCreates a ConvNeXt model. (reference)\n\nArguments\n\nconfig: The size of the model, one of tiny, small, base, large or xlarge.\npretrain: set to true to load pre-trained weights for ImageNet\ninchannels: number of input channels\nnclasses: number of output classes\n\nwarning: Warning\nConvNeXt does not currently support pretrained weights.\n\nSee also Metalhead.convnext.\n\n\n\n\n\n","category":"type"},{"location":"api/hybrid/#The-mid-level-functions","page":"Hybrid CNN architectures","title":"The mid-level functions","text":"","category":"section"},{"location":"api/hybrid/","page":"Hybrid CNN architectures","title":"Hybrid CNN architectures","text":"Metalhead.convmixer\nMetalhead.convnext","category":"page"},{"location":"api/hybrid/#Metalhead.convmixer","page":"Hybrid CNN architectures","title":"Metalhead.convmixer","text":"convmixer(planes::Integer, depth::Integer; kernel_size::Dims{2} = (9, 9),\n          patch_size::Dims{2} = (7, 7), activation = gelu,\n          inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a ConvMixer model. (reference)\n\nArguments\n\nplanes: number of planes in the output of each block\ndepth: number of layers\nkernel_size: kernel size of the convolutional layers\npatch_size: size of the patches\nactivation: activation function used after the convolutional layers\ninchannels: number of input channels\nnclasses: number of classes in the output\n\n\n\n\n\n","category":"function"},{"location":"api/hybrid/#Metalhead.convnext","page":"Hybrid CNN architectures","title":"Metalhead.convnext","text":"convnext(config::Symbol; stochastic_depth_prob = 0.0, layerscale_init = 1.0f-6,\n         inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a ConvNeXt model. (reference)\n\nArguments\n\nconfig: The size of the model, one of tiny, small, base, large or xlarge.\nstochastic_depth_prob: Stochastic depth probability.\nlayerscale_init: Initial value for LayerScale (reference)\ninchannels: number of input channels.\nnclasses: number of output classes\n\n\n\n\n\n","category":"function"},{"location":"#Metalhead","page":"Home","title":"Metalhead","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: Dev) (Image: CI) (Image: Coverage)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Metalhead.jl provides standard machine learning vision models for use with Flux.jl. The architectures in this package make use of pure Flux layers, and they represent the best-practices for creating modules like residual blocks, inception blocks, etc. in Flux. Metalhead also provides some building blocks for more complex models in the Layers module.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"julia> ]add Metalhead","category":"page"},{"location":"#Getting-Started","page":"Home","title":"Getting Started","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"You can find the Metalhead.jl getting started guide here.","category":"page"},{"location":"#Available-models","page":"Home","title":"Available models","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To contribute new models, see our contributing docs.","category":"page"},{"location":"#Image-Classification","page":"Home","title":"Image Classification","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Model Name Constructor Pre-trained?\nAlexNet AlexNet N\nConvMixer ConvMixer N\nConvNeXt ConvNeXt N\nDenseNet DenseNet N\nEfficientNet EfficientNet N\nEfficientNetv2 EfficientNetv2 N\ngMLP gMLP N\nGoogLeNet GoogLeNet N\nInception-v3 Inceptionv3 N\nInception-v4 Inceptionv4 N\nInceptionResNet-v2 InceptionResNetv2 N\nMLPMixer MLPMixer N\nMobileNetv1 MobileNetv1 N\nMobileNetv2 MobileNetv2 N\nMobileNetv3 MobileNetv3 N\nMNASNet MNASNet N\nResMLP ResMLP N\nResNet ResNet Y\nResNeXt ResNeXt Y\nSqueezeNet SqueezeNet Y\nXception Xception N\nWideResNet WideResNet Y\nVGG VGG Y\nVision Transformer ViT Y","category":"page"},{"location":"#Other-Models","page":"Home","title":"Other Models","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Model Name Constructor Pre-trained?\nUNet UNet N","category":"page"}]
}
