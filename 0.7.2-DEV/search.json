[{"body":"Arguments imsize : image size inchannels : number of input channels patch_size : size of the patches embedplanes : the number of channels after the patch embedding depth : number of blocks in the transformer nheads : number of attention heads in the transformer mlpplanes : number of hidden channels in the MLP block in the transformer dropout : dropout rate emb_dropout : dropout rate for the positional embedding layer pool : pooling type, either :class or :mean nclasses : number of classes in the output","id":"docstrings/Metalhead.vit.html#arguments"},{"body":"public   invertedresidual   —   function Create a basic inverted residual block for MobileNet variants ( reference ) .","id":"docstrings/Metalhead.Layers.invertedresidual.html"},{"body":"Arguments nclasses : the number of output classes inception3  does not currently support pretrained weights .","id":"docstrings/Metalhead.inception3.html#arguments"},{"body":"Arguments: inplanes : the number of input feature maps outplanes : a list of the number of output feature maps for each convolution within the residual block downsample : set to  true  to downsample the input stride : a list of the stride of the 3 convolutional layers","id":"docstrings/Metalhead.bottleneck.html#arguments"},{"body":"Arguments kernelsize : size of the convolution kernel (tuple) inplanes : number of input feature maps outplanes : number of output feature maps activation : the activation function for the final layer rev : set to  true  to place the batch norm before the convolution stride : stride of the first convolution kernel pad : padding of the first convolution kernel dilation : dilation of the first convolution kernel bias ,  weight ,  init : initialization for the convolution kernel (see  Flux.Conv ) initβ ,  initγ : initialization for the batch norm (see  Flux.BatchNorm ) ϵ ,  momentum : batch norm parameters (see  Flux.BatchNorm )","id":"docstrings/Metalhead.Layers.depthwise_sep_conv_bn.html#arguments"},{"body":"Arguments ifilters : number of input feature maps ofilters : number of output feature maps depth : number of convolution/convolution + batch norm layers batchnorm : set to  true  to include batch normalization after each convolution","id":"docstrings/Metalhead.vgg_block.html#arguments"},{"body":"Arguments width_mult : Controls the number of output feature maps in each block (with 1 . 0 being the default in the paper; this is usually a value between 0 . 1 and 1 . 4) configs : a  “ list of tuples ”  configuration for each layer that details: k::Integer   -  The size of the convolutional kernel c::Float   -  The multiplier factor for deciding the number of feature maps in the hidden layer t::Integer   -  The number of output feature maps for a given block r::Integer   -  The reduction factor ( >= 1  or  nothing  to skip) for squeeze and excite layers s::Integer   -  The stride of the convolutional kernel a   -  The activation function used in the bottleneck (typically  hardswish  or  relu ) max_width : The maximum number of feature maps in any layer of the network nclasses : the number of output classes","id":"docstrings/Metalhead.mobilenetv3.html#arguments"},{"body":"private   reluadd   —   function Convenience function for  (x, y) -> @. relu(x) + relu(y) . Useful as the  connection  argument for  resnet . See also  addrelu .","id":"docstrings/Metalhead.Layers.reluadd.html"},{"body":"public   depthwise_sep_conv_bn   —   function Create a depthwise separable convolution chain as used in MobileNet v1 . This is sequence of layers: a  kernelsize  depthwise convolution from  inplanes => inplanes a batch norm layer +  activation a  kernelsize  convolution from  inplanes => outplanes a batch norm layer +  activation See Fig .  3 in  reference .","id":"docstrings/Metalhead.Layers.depthwise_sep_conv_bn.html"},{"body":"Arguments cardinality : the number of groups to use for the convolution width : the number of feature maps in each group in the bottleneck widen_factor : the factor by which the width of the bottleneck is increased after each stage connection : the binary function applied to the output of residual and skip paths in a block block_config : a list of the number of residual blocks at each stage nclasses : the number of output classes","id":"docstrings/Metalhead.resnext.html#arguments"},{"body":"Arguments: inplanes : the number of input feature maps outplanes : the number of output feature maps downsample : this argument is ignored but it is needed for compatibility with  resnet .","id":"docstrings/Metalhead.Layers.skip_identity.html#arguments"},{"body":"Arguments size : the size of the model  -  one of  small ,  base ,  large  or  huge patch_size : the size of the patches imsize : the size of the input image drop_path_rate : Stochastic depth rate nclasses : number of output classes See also  Metalhead.mlpmixer .","id":"docstrings/Metalhead.gMLP.html#arguments"},{"body":"Arguments inplanes : number of input feature maps","id":"docstrings/Metalhead.inception_d.html#arguments"},{"body":"Arguments inplanes : number of input feature maps inner_planes : the number of output feature maps within each branch n : the  “ grid size ”  (kernel size) for the convolution layers","id":"docstrings/Metalhead.inception_c.html#arguments"},{"body":"Getting Started You can find the Metalhead . jl getting started guide  here .","id":"README.html#getting-started"},{"body":"Arguments channel_config : the growth rate of the output feature maps within a residual block block_config : a list of the number of residual blocks at each stage shortcut_config : the type of shortcut style (either  :A ,  :B , or  :C ) . shortcut_config  can also be a vector of symbols if different shortcut styles are applied to different residual blocks . block : a function with input  (inplanes, outplanes, downsample=false)  that returns a new residual block (see  Metalhead.basicblock  and  Metalhead.bottleneck ) connection : the binary function applied to the output of residual and skip paths in a block nclasses : the number of output classes Create a ResNet model with a specified depth ( reference ) following  these modification referred as ResNet v1 . 5 . See also  Metalhead.resnet .","id":"docstrings/Metalhead.ResNet.html#arguments"},{"body":"Installation","id":"README.html#installation"},{"body":"private   dense_block   —   function Create a sequence of DenseNet bottlenecks increasing the number of output feature maps by  growth_rates  with each block ( reference ) .","id":"docstrings/Metalhead.dense_block.html"},{"body":"Arguments block : a function with input  (inplanes, outplanes, downsample=false)  that returns a new residual block (see  Metalhead.basicblock  and  Metalhead.bottleneck ) shortcut_config : the type of shortcut style (either  :A ,  :B , or  :C ) :A : uses a  Metalhead.skip_identity  for all residual blocks :B : uses a  Metalhead.skip_projection  for the first residual block and  Metalhead.skip_identity  for the remaining residual blocks :C : uses a  Metalhead.skip_projection  for all residual blocks connection : the binary function applied to the output of residual and skip paths in a block channel_config : the growth rate of the output feature maps within a residual block block_config : a list of the number of residual blocks at each stage nclasses : the number of output classes","id":"docstrings/Metalhead.resnet.html#arguments-1"},{"body":"public   ResMLP   —   struct Creates a model with the ResMLP architecture . ( reference ) .","id":"docstrings/Metalhead.ResMLP.html"},{"body":"Arguments inplanes : the number of input feature maps out_1x1 : the number of output feature maps for the 1x1 convolution (branch 1) red_3x3 : the number of output feature maps for the 3x3 reduction convolution (branch 2) out_3x3 : the number of output feature maps for the 3x3 convolution (branch 2) red_5x5 : the number of output feature maps for the 5x5 reduction convolution (branch 3) out_5x5 : the number of output feature maps for the 5x5 convolution (branch 3) pool_proj : the number of output feature maps for the pooling projection (branch 4)","id":"docstrings/Metalhead._inceptionblock.html#arguments"},{"body":"public   Inception3   —   struct Create an Inception - v3 model ( reference ) . See also  inception3 .","id":"docstrings/Metalhead.Inception3.html"},{"body":"Arguments cardinality : the number of groups to use for the convolution width : the number of feature maps in each group in the bottleneck block_config : a list of the number of residual blocks at each stage nclasses : the number of output classes Create a ResNeXt model with specified configuration .  Currently supported values for  config  are (50, 101) . ( reference ) . Set  pretrain = true  to load the model with pre - trained weights for ImageNet . ResNeXt  does not currently support pretrained weights . See also  Metalhead.resnext .","id":"docstrings/Metalhead.ResNeXt.html#arguments"},{"body":"Arguments: planes : number of input channels . drop_path_rate : Stochastic depth rate . λ : Init value for LayerScale","id":"docstrings/Metalhead.convnextblock.html#arguments"},{"body":"private   googlenet   —   function Create an Inception - v1 model (commonly referred to as GoogLeNet) ( reference ) .","id":"docstrings/Metalhead.googlenet.html"},{"body":"private   cat_channels   —   function Concatenate  x  and  y  (and any  z s) along the channel dimension (third dimension) . Equivalent to  cat(x, y, zs...; dims=3) . Convenient reduction operator for use with  Parallel .","id":"docstrings/Metalhead.Layers.cat_channels.html"},{"body":"Arguments inplanes : number of input feature maps","id":"docstrings/Metalhead.inception_e.html#arguments"},{"body":"private   loadpretrain!   —   function Load the pre - trained weight artifacts matching  <name>.bson  into  model .","id":"docstrings/Metalhead.loadpretrain!.html"},{"body":"private   reluadd   —   function Convenience function for  (x, y) -> @. relu(x) + relu(y) . Useful as the  connection  argument for  resnet . See also  addrelu .","id":"docstrings/Metalhead.reluadd.html"},{"body":"Arguments pretrain : set to  true  to load pre - trained model weights for ImageNet","id":"docstrings/Metalhead.VGG.html#arguments"},{"body":"public   LayerScale   —   function Creates a  Flux.Scale  layer that performs  “ LayerScale ” ( reference ) .","id":"docstrings/Metalhead.Layers.LayerScale.html"},{"body":"public   ViPosEmbedding   —   parametric type Positional embedding layer used by many vision transformer - like models .","id":"docstrings/Metalhead.Layers.ViPosEmbedding.html"},{"body":"Name Module Visibility Category  AlexNet   Metalhead   public   struct   ConvMixer   Metalhead   public   struct   ConvNeXt   Metalhead   public   struct   DenseNet   Metalhead   public   struct   GoogLeNet   Metalhead   public   struct   Inception3   Metalhead   public   struct   ChannelLayerNorm   Metalhead.Layers   public   parametric type   ClassTokens   Metalhead.Layers   public   parametric type   DropPath   Metalhead.Layers   public   function   LayerScale   Metalhead.Layers   public   function   MHAttention   Metalhead.Layers   public   parametric type   PatchEmbedding   Metalhead.Layers   public   function   ViPosEmbedding   Metalhead.Layers   public   parametric type   addrelu   Metalhead.Layers   private   function   cat_channels   Metalhead.Layers   private   function   conv_bn   Metalhead.Layers   public   function   depthwise_sep_conv_bn   Metalhead.Layers   public   function   gated_mlp_block   Metalhead.Layers   public   function   invertedresidual   Metalhead.Layers   public   function   mlp_block   Metalhead.Layers   public   function   reluadd   Metalhead.Layers   private   function   skip_identity   Metalhead.Layers   public   function   skip_projection   Metalhead.Layers   public   function   squeeze_excite   Metalhead.Layers   public   function   swapdims   Metalhead.Layers   private   function   MLPMixer   Metalhead   public   struct   MobileNetv1   Metalhead   public   struct   MobileNetv2   Metalhead   public   struct   MobileNetv3   Metalhead   public   struct   ResMLP   Metalhead   public   struct   ResNeXt   Metalhead   public   struct   ResNet   Metalhead   public   struct   SpatialGatingUnit   Metalhead   private   parametric type   SqueezeNet   Metalhead   public   struct   VGG   Metalhead   public   struct   ViT   Metalhead   public   struct   _inceptionblock   Metalhead   private   function   addrelu   Metalhead   private   function   alexnet   Metalhead   private   function   basicblock   Metalhead   private   function   bottleneck   Metalhead   private   function   bottleneck_v1   Metalhead   private   function   cat_channels   Metalhead   private   function   convmixer   Metalhead   private   function   convnext   Metalhead   private   function   convnextblock   Metalhead   private   function   dense_block   Metalhead   private   function   dense_bottleneck   Metalhead   private   function   densenet   Metalhead   private   function   fire   Metalhead   private   function   gMLP   Metalhead   public   struct   googlenet   Metalhead   private   function   inception3   Metalhead   private   function   inception_a   Metalhead   private   function   inception_b   Metalhead   private   function   inception_c   Metalhead   private   function   inception_d   Metalhead   private   function   inception_e   Metalhead   private   function   loadpretrain!   Metalhead   private   function   mixerblock   Metalhead   private   function   mlpmixer   Metalhead   private   function   mobilenetv1   Metalhead   private   function   mobilenetv2   Metalhead   private   function   mobilenetv3   Metalhead   private   function   reluadd   Metalhead   private   function   resmixerblock   Metalhead   private   function   resnet   Metalhead   private   function   resnext   Metalhead   private   function   resnextblock   Metalhead   private   function   spatial_gating_block   Metalhead   private   function   squeezenet   Metalhead   private   function   swapdims   Metalhead   private   function   transformer_encoder   Metalhead   private   function   transition   Metalhead   private   function   vgg   Metalhead   private   function   vgg_block   Metalhead   private   function   vgg_classifier_layers   Metalhead   private   function   vgg_convolutional_layers   Metalhead   private   function   vit   Metalhead   private   function   weights   Metalhead   private   function ","id":"docstrings.html#docstring-index"},{"body":"Arguments nclasses : the number of output classes","id":"docstrings/Metalhead.googlenet.html#arguments"},{"body":"public   MobileNetv3   —   struct Create a MobileNetv3 model with the specified configuration . ( reference ) . Set  pretrain = true  to load the model with pre - trained weights for ImageNet .","id":"docstrings/Metalhead.MobileNetv3.html"},{"body":"Arguments: imsize : the size of the input image inchannels : the number of channels in the input image patch_size : the size of the patches embedplanes : the number of channels in the embedding norm_layer : the normalization layer  -  by default the identity function but otherwise takes a single argument constructor for a normalization layer like LayerNorm or BatchNorm flatten : set true to flatten the input spatial dimensions after the embedding","id":"docstrings/Metalhead.Layers.PatchEmbedding.html#arguments"},{"body":"public   DropPath   —   function Implements Stochastic Depth  -  equivalent to  Dropout(p; dims = 4)  when  p  ≥ 0 . ( reference )","id":"docstrings/Metalhead.Layers.DropPath.html"},{"body":"private   inception_e   —   function Create an Inception - v3 style - E module (ref: Fig .  7 in  paper ) .","id":"docstrings/Metalhead.inception_e.html"},{"body":"private   spatial_gating_block   —   function Creates a feedforward block based on the gMLP model architecture described in the paper . ( reference )","id":"docstrings/Metalhead.spatial_gating_block.html"},{"body":"private   inception_a   —   function Create an Inception - v3 style - A module (ref: Fig .  5 in  paper ) .","id":"docstrings/Metalhead.inception_a.html"},{"body":"public   skip_projection   —   function Create a skip projection ( reference ) .","id":"docstrings/Metalhead.Layers.skip_projection.html"},{"body":"Arguments size : the size of the model  -  one of  small ,  base ,  large  or  huge patch_size : the size of the patches imsize : the size of the input image drop_path_rate : Stochastic depth rate nclasses : number of output classes See also  Metalhead.mlpmixer .","id":"docstrings/Metalhead.MLPMixer.html#arguments"},{"body":"private   mixerblock   —   function Creates a feedforward block for the MLPMixer architecture . ( reference )","id":"docstrings/Metalhead.mixerblock.html"},{"body":"Arguments planes : number of input channels depth : number of attention blocks nheads : number of attention heads mlp_ratio : ratio of MLP layers to the number of input channels dropout : dropout rate","id":"docstrings/Metalhead.transformer_encoder.html#arguments"},{"body":"Arguments: planes : number of input channels nheads : number of heads qkv_bias : whether to use bias in the layer to get the query, key and value attn_drop : dropout rate after the self - attention layer proj_drop : dropout rate after the projection layer","id":"docstrings/Metalhead.Layers.MHAttention.html#arguments-1"},{"body":"public   MHAttention   —   parametric type Multi - head self - attention layer .","id":"docstrings/Metalhead.Layers.MHAttention.html"},{"body":"private   inception3   —   function Create an Inception - v3 model ( reference ) .","id":"docstrings/Metalhead.inception3.html"},{"body":"private   _inceptionblock   —   function Create an inception module for use in GoogLeNet ( reference ) .","id":"docstrings/Metalhead._inceptionblock.html"},{"body":"Arguments kernel_size : The kernel size of the convolutional layers inplanes : The number of input feature maps hidden_planes : The number of feature maps in the hidden layer outplanes : The number of output feature maps activation : The activation function for the first two convolution layer stride : The stride of the convolutional kernel, has to be either 1 or 2 reduction : The reduction factor for the number of hidden feature maps in a squeeze and excite layer (see  squeeze_excite ) . Must be >= 1 or  nothing  for no squeeze and excite layer .","id":"docstrings/Metalhead.Layers.invertedresidual.html#arguments"},{"body":"public   MobileNetv2   —   struct Create a MobileNetv2 model with the specified configuration . ( reference ) . Set  pretrain  to  true  to load the pretrained weights for ImageNet .","id":"docstrings/Metalhead.MobileNetv2.html"},{"body":"Arguments: inplanes : the number of input feature maps outplanes : the number of output feature maps downsample : set to  true  to downsample the input","id":"docstrings/Metalhead.Layers.skip_projection.html#arguments"},{"body":"Keyword Arguments: config  : VGG convolutional block configuration .  It is defined as a vector of tuples  (output_channels, num_convolutions)  for each block inchannels ::Integer : number of input channels batchnorm ::Bool : set to  true  to use batch normalization after each convolution nclasses ::Integer : number of output classes fcsize : intermediate fully connected layer size (see  Metalhead.vgg_classifier_layers ) dropout : dropout level between fully connected layers Create a VGG style model with specified  depth .  Available values include (11, 13, 16, 19) . ( reference ) . See also  VGG . VGG  does not currently support pretrained weights .","id":"docstrings/Metalhead.VGG.html#keyword-arguments"},{"body":"private   vit   —   function Creates a Vision Transformer (ViT) model . ( reference ) .","id":"docstrings/Metalhead.vit.html"},{"body":"Arguments: planes : the number of planes in the block npatches : the number of patches of the input mlp_ratio : number(s) that determine(s) the number of hidden channels in the token mixing MLP and/or the channel mixing MLP as a ratio to the number of planes in the block . mlp_layer : the MLP layer to use in the block dropout : the dropout rate to use in the MLP blocks drop_path_rate : Stochastic depth rate activation : the activation function to use in the MLP blocks","id":"docstrings/Metalhead.mixerblock.html#arguments"},{"body":"private   bottleneck_v1   —   function Create a bottleneck residual block ( reference ) .  The bottleneck is composed of 3 convolutional layers with all a stride of 1 except the first convolutional layer which has a stride of 2 .","id":"docstrings/Metalhead.bottleneck_v1.html"},{"body":"Arguments pretrain : set to  true  to load pre - trained weights for ImageNet nclasses : the number of output classes","id":"docstrings/Metalhead.AlexNet.html#arguments"},{"body":"Arguments kernelsize : size of the convolution kernel (tuple) inplanes : number of input feature maps outplanes : number of output feature maps activation : the activation function for the final layer rev : set to  true  to place the batch norm before the convolution preact : set to  true  to place the activation function before the batch norm (only compatible with  rev = false ) stride : stride of the convolution kernel pad : padding of the convolution kernel dilation : dilation of the convolution kernel groups : groups for the convolution kernel bias ,  weight ,  init : initialization for the convolution kernel (see  Flux.Conv ) initβ ,  initγ : initialization for the batch norm (see  Flux.BatchNorm ) ϵ ,  momentum : batch norm parameters (see  Flux.BatchNorm )","id":"docstrings/Metalhead.Layers.conv_bn.html#arguments"},{"body":"public   skip_identity   —   function Create a identity projection ( reference ) .","id":"docstrings/Metalhead.Layers.skip_identity.html"},{"body":"Arguments planes : the number of planes in the block npatches : the number of patches of the input mlp_ratio : ratio of the number of hidden channels in the channel mixing MLP to the number of planes in the block norm_layer : the normalisation layer to use dropout : the dropout rate to use in the MLP blocks drop_path_rate : Stochastic depth rate activation : the activation function to use in the MLP blocks","id":"docstrings/Metalhead.spatial_gating_block.html#arguments"},{"body":"private   squeezenet   —   function Create a SqueezeNet ( reference ) .","id":"docstrings/Metalhead.squeezenet.html"},{"body":"Arguments imsize : input image width and height as a tuple config : the configuration for the convolution layers (see  Metalhead.vgg_convolutional_layers ) inchannels : number of input channels batchnorm : set to  true  to use batch normalization after each convolution nclasses : number of output classes fcsize : intermediate fully connected layer size (see  Metalhead.vgg_classifier_layers ) dropout : dropout level between fully connected layers","id":"docstrings/Metalhead.vgg.html#arguments"},{"body":"public   MLPMixer   —   struct Creates a model with the MLPMixer architecture . ( reference ) .","id":"docstrings/Metalhead.MLPMixer.html"},{"body":"public   ChannelLayerNorm   —   parametric type A variant of LayerNorm where the input is normalised along the channel dimension .  The input is expected to have channel dimension with size sz .  It also applies a learnable shift and rescaling after the normalization . Note that this is specifically for inputs with 4 dimensions in the format (H, W, C, N) where H, W are the height and width of the input, C is the number of channels, and N is the batch size .","id":"docstrings/Metalhead.Layers.ChannelLayerNorm.html"},{"body":"Arguments planes : the number of planes in the block npatches : the number of patches of the input norm_layer : the normalisation layer to use","id":"docstrings/Metalhead.SpatialGatingUnit.html#arguments-1"},{"body":"public   gated_mlp_block   —   function Feedforward block based on the implementation in the paper  “ Pay Attention to MLPs ” . ( reference )","id":"docstrings/Metalhead.Layers.gated_mlp_block.html"},{"body":"private   mobilenetv2   —   function Create a MobileNetv2 model . ( reference ) .","id":"docstrings/Metalhead.mobilenetv2.html"},{"body":"Arguments mode : the model configuration, one of  [ :tiny, :small, :base, :large, :huge, :giant, :gigantic ] imsize : image size inchannels : number of input channels patch_size : size of the patches pool : pooling type, either :class or :mean nclasses : number of classes in the output See also  Metalhead.vit .","id":"docstrings/Metalhead.ViT.html#arguments"},{"body":"Arguments block : the type of mixer block to use in the model  -  architecture dependent (a constructor of the form  block(embedplanes, npatches; drop_path_rate, kwargs...) ) imsize : the size of the input image inchannels : the number of input channels norm_layer : the normalization layer to use in the model patch_size : the size of the patches embedplanes : the number of channels after the patch embedding (denotes the hidden dimension) drop_path_rate : Stochastic depth rate depth : the number of blocks in the model nclasses : number of output classes kwargs : additional arguments (if any) to pass to the mixer block .  Will use the defaults if not specified .","id":"docstrings/Metalhead.mlpmixer.html#arguments"},{"body":"Arguments mode : :small or :large for the size of the model (see paper) . width_mult : Controls the number of output feature maps in each block (with 1 . 0 being the default in the paper; this is usually a value between 0 . 1 and 1 . 4) pretrain : whether to load the pre - trained weights for ImageNet nclasses : the number of output classes See also  Metalhead.mobilenetv3 .","id":"docstrings/Metalhead.MobileNetv3.html#arguments"},{"body":"public   squeeze_excite   —   function Squeeze and excitation layer used by MobileNet variants ( reference ) .","id":"docstrings/Metalhead.Layers.squeeze_excite.html"},{"body":"private   bottleneck   —   function Create a bottleneck residual block ( reference ) .  The bottleneck is composed of 3 convolutional layers each with the given  stride . By default,  stride  implements  “ ResNet v1 . 5 ” which uses  stride == [1, 2, 1]  when  downsample == true . This version is standard across various ML frameworks . The original paper uses  stride == [2, 1, 1]  when  downsample == true  instead .","id":"docstrings/Metalhead.bottleneck.html"},{"body":"Arguments inplanes : number of input feature maps to the full sequence growth_rates : the growth (additive) rates of output feature maps after each block (a vector of  k s from the ref)","id":"docstrings/Metalhead.dense_block.html#arguments"},{"body":"private   inception_b   —   function Create an Inception - v3 style - B module (ref: Fig .  10 in  paper ) .","id":"docstrings/Metalhead.inception_b.html"},{"body":"private   inception_d   —   function Create an Inception - v3 style - D module (ref:  pytorch ) .","id":"docstrings/Metalhead.inception_d.html"},{"body":"Arguments imsize : tuple  (width, height, channels)  indicating the size after the convolution layers (see  Metalhead.vgg_convolutional_layers ) nclasses : number of output classes fcsize : input and output size of the intermediate fully connected layer dropout : the dropout level between each fully connected layer","id":"docstrings/Metalhead.vgg_classifier_layers.html#arguments"},{"body":"Arguments inplanes : number of input feature maps squeeze_planes : number of intermediate feature maps expand1x1_planes : number of output feature maps for the 1x1 expansion convolution expand3x3_planes : number of output feature maps for the 3x3 expansion convolution","id":"docstrings/Metalhead.fire.html#arguments"},{"body":"Arguments planes : Size of channel dimension in the input . λ : initialisation value for the learnable diagonal matrix .","id":"docstrings/Metalhead.Layers.LayerScale.html#arguments"},{"body":"Arguments gate_layer : Layer to use for the gating . inplanes : Number of dimensions in the input . hidden_planes : Number of dimensions in the intermediate layer . outplanes : Number of dimensions in the output  -  by default it is the same as  inplanes . dropout : Dropout rate . activation : Activation function to use .","id":"docstrings/Metalhead.Layers.gated_mlp_block.html#arguments"},{"body":"public   ViT   —   struct Creates a Vision Transformer (ViT) model . ( reference ) .","id":"docstrings/Metalhead.ViT.html"},{"body":"private   mlpmixer   —   function Creates a model with the MLPMixer architecture . ( reference ) .","id":"docstrings/Metalhead.mlpmixer.html"},{"body":"Arguments width_mult : Controls the number of output feature maps in each block (with 1 . 0 being the default in the paper) configs : A  “ list of tuples ”  configuration for each layer that details: t : The expansion factor that controls the number of feature maps in the bottleneck layer c : The number of output feature maps n : The number of times a block is repeated s : The stride of the convolutional kernel a : The activation function used in the bottleneck layer max_width : The maximum number of feature maps in any layer of the network nclasses : The number of output classes","id":"docstrings/Metalhead.mobilenetv2.html#arguments"},{"body":"public   PatchEmbedding   —   function Patch embedding layer used by many vision transformer - like models to split the input image into patches .","id":"docstrings/Metalhead.Layers.PatchEmbedding.html"},{"body":"Arguments channels : the number of input/output feature maps reduction = 4 : the reduction factor for the number of hidden feature maps (must be >= 1)","id":"docstrings/Metalhead.Layers.squeeze_excite.html#arguments"},{"body":"private   cat_channels   —   function Concatenate  x  and  y  (and any  z s) along the channel dimension (third dimension) . Equivalent to  cat(x, y, zs...; dims=3) . Convenient reduction operator for use with  Parallel .","id":"docstrings/Metalhead.cat_channels.html"},{"body":"private   mobilenetv3   —   function Create a MobileNetv3 model . ( reference ) .","id":"docstrings/Metalhead.mobilenetv3.html"},{"body":"Metalhead Dev CI Coverage Metalhead . jl  provides standard machine learning vision models for use with  Flux . jl .  The architectures in this package make use of pure Flux layers, and they represent the best - practices for creating modules like residual blocks, inception blocks, etc .  in Flux .  Metalhead also provides some building blocks for more complex models in the Layers module .","id":"README.html#metalhead"},{"body":"Arguments nclasses : the number of output classes","id":"docstrings/Metalhead.alexnet.html#arguments"},{"body":"private   dense_bottleneck   —   function Create a Densenet bottleneck layer ( reference ) .","id":"docstrings/Metalhead.dense_bottleneck.html"},{"body":"private   vgg   —   function Create a VGG model ( reference ) .","id":"docstrings/Metalhead.vgg.html"},{"body":"public   MobileNetv1   —   struct Create a MobileNetv1 model with the baseline configuration ( reference ) . Set  pretrain  to  true  to load the pretrained weights for ImageNet .","id":"docstrings/Metalhead.MobileNetv1.html"},{"body":"public   ResNeXt   —   struct Create a ResNeXt model ( reference ) .","id":"docstrings/Metalhead.ResNeXt.html"},{"body":"public   ClassTokens   —   parametric type Appends class tokens to an input with embedding dimension  dim  for use in many vision transformer models .","id":"docstrings/Metalhead.Layers.ClassTokens.html"},{"body":"Arguments inplanes : number of input feature maps outplanes : number of output feature maps","id":"docstrings/Metalhead.transition.html#arguments"},{"body":"Arguments size : the size of the model  -  one of  small ,  base ,  large  or  huge patch_size : the size of the patches imsize : the size of the input image drop_path_rate : Stochastic depth rate nclasses : number of output classes See also  Metalhead.mlpmixer .","id":"docstrings/Metalhead.ResMLP.html#arguments"},{"body":"Arguments p : rate of Stochastic Depth .","id":"docstrings/Metalhead.Layers.DropPath.html#arguments"},{"body":"public   ConvMixer   —   struct Creates a ConvMixer model . ( reference )","id":"docstrings/Metalhead.ConvMixer.html"},{"body":"private   densenet   —   function Create a DenseNet model ( reference ) .","id":"docstrings/Metalhead.densenet.html"},{"body":"private   convnextblock   —   function Creates a single block of ConvNeXt . ( reference )","id":"docstrings/Metalhead.convnextblock.html"},{"body":"public   GoogLeNet   —   struct Create an Inception - v1 model (commonly referred to as  GoogLeNet ) ( reference ) .","id":"docstrings/Metalhead.GoogLeNet.html"},{"body":"Arguments pretrain : set to  true  to load the pre - trained weights for ImageNet nclasses : the number of output classes Inception3  does not currently support pretrained weights .","id":"docstrings/Metalhead.Inception3.html#arguments"},{"body":"Arguments depth : depth of the ResNet model .  Options include (18, 34, 50, 101, 152) . nclasses : the number of output classes Only  ResNet(50)  currently supports pretrained weights . For  ResNet(18)  and  ResNet(34) , the parameter - free shortcut style (type  :A ) is used in the first block and the three other blocks use type  :B  connection (following the implementation in PyTorch) .  The published version of ResNet(18)  and  ResNet(34)  used type  :A  shortcuts for all four blocks .  The example below shows how to create a 18 or 34 - layer  ResNet  using only type  :A shortcuts: The bottleneck of the orginal ResNet model has a stride of 2 on the first convolutional layer when downsampling (instead of the second convolutional layers as in ResNet v1 . 5) .  The architecture of the orignal ResNet model can be obtained as shown below:","id":"docstrings/Metalhead.ResNet.html#arguments-1"},{"body":"private   SpatialGatingUnit   —   parametric type Creates a spatial gating unit as described in the gMLP paper . ( reference )","id":"docstrings/Metalhead.SpatialGatingUnit.html"},{"body":"Arguments: inchannels : number of input channels . depths : list with configuration for depth of each block planes : list with configuration for number of output channels in each block drop_path_rate : Stochastic depth rate . λ : Init value for  LayerScale nclasses : number of output classes","id":"docstrings/Metalhead.convnext.html#arguments"},{"body":"Arguments nblocks : number of dense blocks between transitions growth_rate : the output feature map growth rate of dense blocks (i . e .   k  in the ref) reduction : the factor by which the number of feature maps is scaled across each transition nclasses : the number of output classes","id":"docstrings/Metalhead.densenet.html#arguments-1"},{"body":"public   ConvNeXt   —   struct Creates a ConvNeXt model . ( reference )","id":"docstrings/Metalhead.ConvNeXt.html"},{"body":"private   addrelu   —   function Convenience function for  (x, y) -> @. relu(x + y) . Useful as the  connection  argument for  resnet . See also  reluadd .","id":"docstrings/Metalhead.Layers.addrelu.html"},{"body":"public   gMLP   —   struct Creates a model with the gMLP architecture . ( reference ) .","id":"docstrings/Metalhead.gMLP.html"},{"body":"private   resmixerblock   —   function Creates a block for the ResMixer architecture . ( reference ) .","id":"docstrings/Metalhead.resmixerblock.html"},{"body":"private   basicblock   —   function Create a basic residual block ( reference ) .","id":"docstrings/Metalhead.basicblock.html"},{"body":"Available models Model Name Function Pre - trained?  VGG   VGG  N  ResNet   ResNet  N  GoogLeNet   GoogLeNet  N  Inception - v3   Inception3  N  SqueezeNet   SqueezeNet  N  DenseNet   DenseNet  N  ResNeXt   ResNeXt  N  MobileNetv1   MobileNetv1  N  MobileNetv2   MobileNetv2  N  MobileNetv3   MobileNetv3  N  MLPMixer   MLPMixer  N  ResMLP   ResMLP  N  gMLP   gMLP  N  ViT   ViT  N  ConvNeXt   ConvNeXt  N  ConvMixer   ConvMixer  N","id":"README.html#available-models"},{"body":"private   transformer_encoder   —   function transformer _ encoder(planes, depth, nheads; mlp _ ratio = 4 . 0, dropout = 0 . ) Transformer as used in the base ViT architecture . ( reference ) .","id":"docstrings/Metalhead.transformer_encoder.html"},{"body":"Quickstart Using a model from Metalhead is as simple as selecting a model from the table of  available models .  For example, below we use the ResNet - 18 model . Now, we can use this model with Flux like any other model .  Below, we train it on some randomly generated data .","id":"docs/tutorials/quickstart.html#quickstart"},{"body":"private   mobilenetv1   —   function Create a MobileNetv1 model ( reference ) .","id":"docstrings/Metalhead.mobilenetv1.html"},{"body":"private   weights   —   function Load the pre - trained weights for  model  using the stored artifacts .","id":"docstrings/Metalhead.weights.html"},{"body":"private   swapdims   —   function Convenience function for permuting the dimensions of an array . perm  is a vector or tuple specifying a permutation of the input dimensions . Equivalent to  permutedims(x, perm) .","id":"docstrings/Metalhead.swapdims.html"},{"body":"Arguments width_mult : Controls the number of output feature maps in each block (with 1 . 0 being the default in the paper; this is usually a value between 0 . 1 and 1 . 4) pretrain : Whether to load the pre - trained weights for ImageNet nclasses : The number of output classes See also  Metalhead.mobilenetv2 .","id":"docstrings/Metalhead.MobileNetv2.html#arguments"},{"body":"private   addrelu   —   function Convenience function for  (x, y) -> @. relu(x + y) . Useful as the  connection  argument for  resnet . See also  reluadd .","id":"docstrings/Metalhead.addrelu.html"},{"body":"public   DenseNet   —   struct Create a DenseNet model ( reference ) . See also  densenet .","id":"docstrings/Metalhead.DenseNet.html"},{"body":"Arguments: inplanes : the number of input feature maps outplanes : a list of the number of output feature maps for each convolution within the residual block downsample : set to  true  to downsample the input","id":"docstrings/Metalhead.bottleneck_v1.html#arguments"},{"body":"Arguments inplanes : number of input feature maps outplanes : number of output feature maps on bottleneck branch (and scaling factor for inner feature maps; see ref)","id":"docstrings/Metalhead.dense_bottleneck.html#arguments"},{"body":"private   vgg_classifier_layers   —   function Create VGG classifier (fully connected) layers ( reference ) .","id":"docstrings/Metalhead.vgg_classifier_layers.html"},{"body":"Arguments inplanes : number of input feature maps","id":"docstrings/Metalhead.inception_b.html#arguments"},{"body":"Arguments nblocks : number of dense blocks between transitions growth_rate : the output feature map growth rate of dense blocks (i . e .   k  in the paper) reduction : the factor by which the number of feature maps is scaled across each transition nclasses : the number of output classes Create a DenseNet model with specified configuration .  Currently supported values are (121, 161, 169, 201) ( reference ) . Set  pretrain = true  to load the model with pre - trained weights for ImageNet . DenseNet  does not currently support pretrained weights . See also  Metalhead.densenet .","id":"docstrings/Metalhead.DenseNet.html#arguments"},{"body":"private   resnext   —   function Create a ResNeXt model ( reference ) .","id":"docstrings/Metalhead.resnext.html"},{"body":"private   fire   —   function Create a fire module ( reference ) .","id":"docstrings/Metalhead.fire.html"},{"body":"private   transition   —   function Create a DenseNet transition sequence ( reference ) .","id":"docstrings/Metalhead.transition.html"},{"body":"private   alexnet   —   function Create an AlexNet model ( reference ) .","id":"docstrings/Metalhead.alexnet.html"},{"body":"Arguments width_mult : Controls the number of output feature maps in each block (with 1 . 0 being the default in the paper) configs : A  “ list of tuples ”  configuration for each layer that details: dw : Set true to use a depthwise separable convolution or false for regular convolution o : The number of output feature maps s : The stride of the convolutional kernel r : The number of time this configuration block is repeated activate : The activation function to use throughout the network inchannels : The number of input feature maps `` fcsize : The intermediate fully - connected size between the convolution and final layers nclasses : The number of output classes","id":"docstrings/Metalhead.mobilenetv1.html#arguments"},{"body":"Arguments norm : the normalisation layer to use proj : the projection layer to use Creates a spatial gating unit as described in the gMLP paper . ( reference )","id":"docstrings/Metalhead.SpatialGatingUnit.html#arguments"},{"body":"public   mlp_block   —   function Feedforward block used in many MLPMixer - like and vision - transformer models .","id":"docstrings/Metalhead.Layers.mlp_block.html"},{"body":"private   resnextblock   —   function Create a basic residual block as defined in the paper for ResNeXt ( reference ) .","id":"docstrings/Metalhead.resnextblock.html"},{"body":"Arguments mode : the mode of the model, either  :base ,  :small  or  :large inchannels : number of channels in the input activation : activation function used after the convolutional layers nclasses : number of classes in the output","id":"docstrings/Metalhead.ConvMixer.html#arguments"},{"body":"private   swapdims   —   function Convenience function for permuting the dimensions of an array . perm  is a vector or tuple specifying a permutation of the input dimensions . Equivalent to  permutedims(x, perm) .","id":"docstrings/Metalhead.Layers.swapdims.html"},{"body":"Arguments width_mult : Controls the number of output feature maps in each block (with 1 . 0 being the default in the paper; this is usually a value between 0 . 1 and 1 . 4) pretrain : Whether to load the pre - trained weights for ImageNet nclasses : The number of output classes See also  Metalhead.mobilenetv1 .","id":"docstrings/Metalhead.MobileNetv1.html#arguments"},{"body":"public   AlexNet   —   struct Create a  AlexNet . See also  alexnet . AlexNet  does not currently support pretrained weights .","id":"docstrings/Metalhead.AlexNet.html"},{"body":"Arguments: inplanes : the number of input feature maps outplanes : the number of output feature maps cardinality : the number of groups to use for the convolution width : the number of feature maps in each group in the bottleneck downsample : set to  true  to downsample the input","id":"docstrings/Metalhead.resnextblock.html#arguments"},{"body":"private   inception_c   —   function Create an Inception - v3 style - C module (ref: Fig .  6 in  paper ) .","id":"docstrings/Metalhead.inception_c.html"},{"body":"Arguments: inchannels : number of input channels . drop_path_rate : Stochastic depth rate . λ : Init value for  LayerScale nclasses : number of output classes See also  Metalhead.convnext .","id":"docstrings/Metalhead.ConvNeXt.html#arguments"},{"body":"public   SqueezeNet   —   struct Create a SqueezeNet ( reference ) . Set  pretrain=true  to load the model with pre - trained weights for ImageNet . SqueezeNet  does not currently support pretrained weights . See also  squeezenet .","id":"docstrings/Metalhead.SqueezeNet.html"},{"body":"Arguments inplanes : Number of dimensions in the input . hidden_planes : Number of dimensions in the intermediate layer . outplanes : Number of dimensions in the output  -  by default it is the same as  inplanes . dropout : Dropout rate . activation : Activation function to use .","id":"docstrings/Metalhead.Layers.mlp_block.html#arguments"},{"body":"Arguments inplanes : the number of input feature maps to the first dense block growth_rates : the growth rates of output feature maps within each dense_block  (a vector of vectors) reduction : the factor by which the number of feature maps is scaled across each transition nclasses : the number of output classes Create a DenseNet model ( reference ) .","id":"docstrings/Metalhead.densenet.html#arguments"},{"body":"private   vgg_convolutional_layers   —   function Create VGG convolution layers ( reference ) .","id":"docstrings/Metalhead.vgg_convolutional_layers.html"},{"body":"Arguments planes : the number of planes in the block npatches : the number of patches of the input mlp_ratio : ratio of the number of hidden channels in the channel mixing MLP to the number of planes in the block mlp_layer : the MLP block to use dropout : the dropout rate to use in the MLP blocks drop_path_rate : Stochastic depth rate activation : the activation function to use in the MLP blocks λ : initialisation constant for the LayerScale","id":"docstrings/Metalhead.resmixerblock.html#arguments"},{"body":"private   convmixer   —   function Creates a ConvMixer model . ( reference )","id":"docstrings/Metalhead.convmixer.html"},{"body":"public   ResNet   —   struct Create a  ResNet  model ( reference ) . See also  resnet .","id":"docstrings/Metalhead.ResNet.html"},{"body":"Arguments block : a function with input  (inplanes, outplanes, downsample=false)  that returns a new residual block (see  Metalhead.basicblock  and  Metalhead.bottleneck ) residuals : a 2 - tuple of functions with input  (inplanes, outplanes, downsample=false) , each of which will return a function that will be used as a new  “ skip ”  path to match a residual block . Metalhead.skip_identity  and  Metalhead.skip_projection  can be used here . connection : the binary function applied to the output of residual and skip paths in a block channel_config : the growth rate of the output feature maps within a residual block block_config : a list of the number of residual blocks at each stage nclasses : the number of output classes Create a ResNet model ( reference ) .","id":"docstrings/Metalhead.resnet.html#arguments"},{"body":"Arguments pretrain : set to  true  to load the model with pre - trained weights for ImageNet nclasses : the number of output classes GoogLeNet  does not currently support pretrained weights . See also  googlenet .","id":"docstrings/Metalhead.GoogLeNet.html#arguments"},{"body":"private   resnet   —   function Create a ResNet model ( reference ) .","id":"docstrings/Metalhead.resnet.html"},{"body":"public   conv_bn   —   function Create a convolution + batch normalization pair with activation .","id":"docstrings/Metalhead.Layers.conv_bn.html"},{"body":"Arguments: nheads : Number of heads qkv_layer : layer to be used for getting the query, key and value attn_drop : dropout rate after the self - attention layer projection : projection layer to be used after self - attention Multi - head self - attention layer .","id":"docstrings/Metalhead.Layers.MHAttention.html#arguments"},{"body":"Arguments inplanes : number of input feature maps pool_proj : the number of output feature maps for the pooling projection","id":"docstrings/Metalhead.inception_a.html#arguments"},{"body":"public   VGG   —   struct Construct a VGG model with the specified input image size .  Typically, the image size is  (224, 224) .","id":"docstrings/Metalhead.VGG.html"},{"body":"Arguments config : vector of tuples  (output_channels, num_convolutions) for each block (see  Metalhead.vgg_block ) batchnorm : set to  true  to include batch normalization after each convolution inchannels : number of input channels","id":"docstrings/Metalhead.vgg_convolutional_layers.html#arguments"},{"body":"private   convnext   —   function Creates the layers for a ConvNeXt model . ( reference )","id":"docstrings/Metalhead.convnext.html"},{"body":"Arguments planes : number of planes in the output of each block depth : number of layers inchannels : number of channels in the input kernel_size : kernel size of the convolutional layers patch_size : size of the patches activation : activation function used after the convolutional layers nclasses : number of classes in the output","id":"docstrings/Metalhead.convmixer.html#arguments"},{"body":"Arguments: inplanes : the number of input feature maps outplanes : a list of the number of output feature maps for each convolution within the residual block downsample : set to  true  to downsample the input","id":"docstrings/Metalhead.basicblock.html#arguments"},{"body":"private   vgg_block   —   function A VGG block of convolution layers ( reference ) .","id":"docstrings/Metalhead.vgg_block.html"}]